{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYyiSBrLU3_O"
      },
      "source": [
        "# 0. Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Цель практики - тренировка подбора гиперпараметров моделей МО:\n",
        "* Обучить две модели: логистическую регрессию и случайный лес;  \n",
        "* Выполнить подбор гиперпараметров с помощью базовых (`GridSeachCV, RandomizedSearchCV`) и продвинутых (`Hyperopt, Optuna`) методов оптимизации так, чтобы улучшать итоговую метрику;   \n",
        "* Провести сравнение и понять преимущества и недостатки каждого из методов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqK5u2bBT46P"
      },
      "outputs": [],
      "source": [
        "#импорт библиотек\n",
        "import numpy as np #для матричных вычислений\n",
        "import pandas as pd #для анализа и предобработки данных\n",
        "import matplotlib.pyplot as plt #для визуализации\n",
        "import seaborn as sns #для визуализации\n",
        "\n",
        "from sklearn import linear_model #линейные модели\n",
        "from sklearn import tree #деревья решений\n",
        "from sklearn import ensemble #ансамбли\n",
        "from sklearn import metrics #метрики\n",
        "from sklearn import preprocessing #предобработка\n",
        "from sklearn.model_selection import train_test_split #сплитование выборки\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "HZSz6oiyUXR7",
        "outputId": "74dc1bf2-3c46-4a39-d5d8-243ce49ff38d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ba01a4c-6375-4eb2-b8ef-91b36ccbd647\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>D1767</th>\n",
              "      <th>D1768</th>\n",
              "      <th>D1769</th>\n",
              "      <th>D1770</th>\n",
              "      <th>D1771</th>\n",
              "      <th>D1772</th>\n",
              "      <th>D1773</th>\n",
              "      <th>D1774</th>\n",
              "      <th>D1775</th>\n",
              "      <th>D1776</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497009</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132956</td>\n",
              "      <td>0.678031</td>\n",
              "      <td>0.273166</td>\n",
              "      <td>0.585445</td>\n",
              "      <td>0.743663</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.606291</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111209</td>\n",
              "      <td>0.803455</td>\n",
              "      <td>0.106105</td>\n",
              "      <td>0.411754</td>\n",
              "      <td>0.836582</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.480124</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209791</td>\n",
              "      <td>0.610350</td>\n",
              "      <td>0.356453</td>\n",
              "      <td>0.517720</td>\n",
              "      <td>0.679051</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538825</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.196344</td>\n",
              "      <td>0.724230</td>\n",
              "      <td>0.235606</td>\n",
              "      <td>0.288764</td>\n",
              "      <td>0.805110</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.517794</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494734</td>\n",
              "      <td>0.781422</td>\n",
              "      <td>0.154361</td>\n",
              "      <td>0.303809</td>\n",
              "      <td>0.812646</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1777 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ba01a4c-6375-4eb2-b8ef-91b36ccbd647')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ba01a4c-6375-4eb2-b8ef-91b36ccbd647 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ba01a4c-6375-4eb2-b8ef-91b36ccbd647');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
              "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
              "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
              "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
              "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
              "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
              "\n",
              "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
              "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
              "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
              "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
              "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
              "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
              "\n",
              "   D1774  D1775  D1776  \n",
              "0      0      0      0  \n",
              "1      0      1      0  \n",
              "2      0      0      0  \n",
              "3      0      0      0  \n",
              "4      0      0      0  \n",
              "\n",
              "[5 rows x 1777 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# подключаем google диск, где у нас хранятся данные\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# берем необходимый нам файл с диска, указав путь\n",
        "data = pd.read_csv('./_train_sem09 (1).csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "iaMHeeGKWU-s",
        "outputId": "7f9b96e3-39db-4ce8-e58f-47aaad85f3af"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Посмотрим на сбалансированность классов:\n",
        "sns.countplot(data=data, x='Activity');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nndS265eWvuv"
      },
      "source": [
        "Довольно сбалансированные классы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6YZyEO9nkwy"
      },
      "outputs": [],
      "source": [
        "# Создадим матрицу наблюдений X и столбец с ответами y\n",
        "X = data.drop(['Activity'], axis=1)\n",
        "y = data['Activity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVIWWTton0v2"
      },
      "outputs": [],
      "source": [
        "# Разделим данные на обучающую и тестовую части\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 1, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clibb78qoGJS"
      },
      "source": [
        "# 1. Обучаем две модели: логистическую регрессию и случайный лес"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99p-zv1SZWzz"
      },
      "source": [
        "## 1.1. Создаем объект класса **логистическая регрессия** (**LR**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jV0Bkb0n3Qg",
        "outputId": "8ed741d7-1bc2-48f0-cd0e-ca36fe394bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score на обучающем наборе: 0.87\n",
            "f1_score на тестовом наборе: 0.79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Создаем объект класса логистическая регрессия\n",
        "lr = linear_model.LogisticRegression(max_iter = 50)\n",
        "# Обучаем модель\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Выводим значения метрики:\n",
        "#для тренировочных данных\n",
        "y_train_pred_lr = lr.predict(X_train)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred_lr))) \n",
        "#для тестовых данных\n",
        "y_test_pred_lr = lr.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred_lr)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIQF4Xx7seN1"
      },
      "source": [
        "Без дополнительной настройки для **Логистической регрессии** получены значения метрики _F1-score_ на: обучающем наборе 0.87, тестовом наборе 0.79."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krgEtfPjq66x"
      },
      "source": [
        "## 1.2. Создаем объект класса **случайный лес** (**RF**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwoEjGwWrBZ1",
        "outputId": "cbe2af73-a7c6-447c-a373-4e1617012a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score на обучающем наборе: 1.00\n",
            "f1_score на тестовом наборе: 0.81\n"
          ]
        }
      ],
      "source": [
        "#Создаем объект класса случайный лес\n",
        "rf = ensemble.RandomForestClassifier(random_state=42)\n",
        "# Обучаем модель\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Выводим значения метрики\n",
        "#для тренировочных данных\n",
        "y_train_pred_rf = rf.predict(X_train)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred_rf)))\n",
        "#для тестовых данных\n",
        "y_test_pred_rf = rf.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred_rf)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScANh3bXslSQ"
      },
      "source": [
        "Без дополнительной настройки для **Случайного леса** получены значения метрики _F1-score_ на: обучающем наборе 1.0, тестовом наборе 0.81. Методом случайного леса метрика _F1-score_ на тестовом наборе несколько лучше, чем методом логистической регрессии 0.81 против 0.79."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw4SwYrUtgan"
      },
      "source": [
        "# 2. Подбор гиперпараметров с помощью базовых методов оптимизации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUCHsJo0ZdBV"
      },
      "source": [
        "## 2.1. Подбор гиперпараметров для алгоритма **Логистической регрессии** методом **GridSearchCV (GSCV).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJvFJZMktcDP",
        "outputId": "ec8f0e28-e989-4466-f54d-cbb3f2b4516f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV \u001b[38;5;66;03m# Импортируем библиотеку GridSearchCV\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Создадим словарь искомых гиперпараметров\u001b[39;00m\n\u001b[0;32m      4\u001b[0m param_grid_lr \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m               {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenalty\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] , \u001b[38;5;66;03m# тип регуляризации\u001b[39;00m\n\u001b[0;32m      6\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# алгоритм оптимизации\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m))}, \u001b[38;5;66;03m# уровень силы регурялизации\u001b[39;00m\n\u001b[0;32m      8\u001b[0m               \n\u001b[0;32m      9\u001b[0m               {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenalty\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m] ,\n\u001b[0;32m     10\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     11\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m))}\n\u001b[0;32m     12\u001b[0m                 ]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Вызываем класс GridSearchCV и передаем модель LogisticRegression и прочие данные для расчетов,\u001b[39;00m\n\u001b[0;32m     14\u001b[0m grid_search_lr \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     15\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mlinear_model\u001b[38;5;241m.\u001b[39mLogisticRegression(\n\u001b[0;32m     16\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, \u001b[38;5;66;03m#генератор случайных чисел\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     22\u001b[0m )  \n",
            "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV # Импортируем библиотеку GridSearchCV\n",
        "\n",
        "# Создадим словарь искомых гиперпараметров\n",
        "param_grid_lr = [\n",
        "              {'penalty': ['l2', None] , # тип регуляризации\n",
        "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
        "               'C': list(np.linspace(0.01, 1, 10, dtype=float))}, # уровень силы регурялизации\n",
        "              \n",
        "              {'penalty': ['l1', 'l2'] ,\n",
        "              'solver': ['liblinear', 'saga'],\n",
        "               'C': list(np.linspace(0.01, 1, 10, dtype=float))}\n",
        "                ]\n",
        "# Вызываем класс GridSearchCV и передаем модель LogisticRegression и прочие данные для расчетов,\n",
        "grid_search_lr = GridSearchCV(\n",
        "    estimator=linear_model.LogisticRegression(\n",
        "        random_state=42, #генератор случайных чисел\n",
        "        max_iter=50 #количество итераций на сходимость\n",
        "    ), \n",
        "    param_grid=param_grid_lr, \n",
        "    cv=5, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "\n",
        "%%time\n",
        "\n",
        "grid_search_lr.fit(X_train, y_train) \n",
        "y_train_pred = grid_search_lr.predict(X_train)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "y_test_pred = grid_search_lr.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_lr.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85TWVm1jxlON"
      },
      "source": [
        "Для **Логистической регрессии** получены следующие значения _F1-score_ при подборе гиперпараметров методом GridSearchCV на: обучающем наборе - 0.86, тестовом наборе - 0.78. Улучшить метрику для логистической регрессии с помощью **GSCV** не удалось."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "GULZGI6Rz7pV",
        "outputId": "bac956e9-2522-4491-b1cf-28d57e431031"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-078d03cc-519d-4388-a578-3b69da0aff43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_C</th>\n",
              "      <th>param_penalty</th>\n",
              "      <th>param_solver</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.774005</td>\n",
              "      <td>0.123558</td>\n",
              "      <td>0.030203</td>\n",
              "      <td>0.002719</td>\n",
              "      <td>0.01</td>\n",
              "      <td>l2</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
              "      <td>0.736667</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.746667</td>\n",
              "      <td>0.754667</td>\n",
              "      <td>0.015684</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.297659</td>\n",
              "      <td>0.542160</td>\n",
              "      <td>0.041453</td>\n",
              "      <td>0.020640</td>\n",
              "      <td>0.01</td>\n",
              "      <td>l2</td>\n",
              "      <td>sag</td>\n",
              "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
              "      <td>0.738333</td>\n",
              "      <td>0.763333</td>\n",
              "      <td>0.781667</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.745000</td>\n",
              "      <td>0.754667</td>\n",
              "      <td>0.015861</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-078d03cc-519d-4388-a578-3b69da0aff43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-078d03cc-519d-4388-a578-3b69da0aff43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-078d03cc-519d-4388-a578-3b69da0aff43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
              "0       0.774005      0.123558         0.030203        0.002719    0.01   \n",
              "1       5.297659      0.542160         0.041453        0.020640    0.01   \n",
              "\n",
              "  param_penalty param_solver                                           params  \\\n",
              "0            l2        lbfgs  {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}   \n",
              "1            l2          sag    {'C': 0.01, 'penalty': 'l2', 'solver': 'sag'}   \n",
              "\n",
              "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
              "0           0.736667           0.765000           0.780000              0.745   \n",
              "1           0.738333           0.763333           0.781667              0.745   \n",
              "\n",
              "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
              "0           0.746667         0.754667        0.015684               21  \n",
              "1           0.745000         0.754667        0.015861               21  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Взглянем на результаты кросс-валидации\n",
        "result_cv = pd.DataFrame(grid_search_lr.cv_results_)\n",
        "result_cv.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n17h4It0p3z",
        "outputId": "318e6bbd-91a0-403e-db31-965c78159e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
              "       'param_C', 'param_penalty', 'param_solver', 'params',\n",
              "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
              "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
              "       'std_test_score', 'rank_test_score'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_cv.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "wZJ1MsQn0Rxh",
        "outputId": "6492bf6e-5970-4c9d-9c06-9487373f5470"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAH5CAYAAABqLE17AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABY/ElEQVR4nO3deVyVdfr/8TcHQVNDwAQP6qgtCpaZDtnikkuNGwhqTWYqjqmZuZQVYqYoTqnMaDnuZrm0jI67oC3i2OISk0tNX1HHXDKRRUXELUE4vz/8dU9nWOtwew6H17PHeTzO+dzL5zoHpIuL6/7cHjabzSYAAADATVicHQAAAABQnkhwAQAA4FZIcAEAAOBWSHABAADgVkhwAQAA4FZIcAEAAOBWSHABAG6tadOm+uGHH5wdBoCbqIqzA0DF1bJlS+P51atX5e3tLU9PT0nSlClT1LNnT2eFBsBBp06dUufOnVW9enVjrEGDBtq0aZMyMzM1adIk/d///Z/OnDmjbdu2qX79+k6MtuI6fvy43nzzTSUnJ+v69esKCgpS7969NXDgQOPnKYBfjwQXv9n+/fuN5506ddKf//xnPfzww06MCEB5+/rrr1Wliv3/KiwWi9q1a6dnn31Wffv2dVJkznX9+vVCn8uvdfLkSf3xj39U7969lZCQoICAAB07dkzz5s3T5cuX5ePjU07RApUPLQowTUFBgRYvXqxHH31UDzzwgMaMGaPs7GxJN6pDTZs2VcuWLY3H3XffrTlz5hjH/+8+ISEhWr16tSQpNzdXr7/+utq2bau2bdvq9ddfV25uriQpOTlZwcHBxnGPP/64/vOf/xjnHT16tNq0aaPf//73evrpp3XkyBFj25kzZzR48GCFhoYWGdMvzZkzRy+//LIk6dq1a+rfv7/+8pe/lGmemJgYTZo0SX/605/UsmVL9e/fX6mpqZKk4cOHq2XLlrrvvvvs3v+kSZMkyfhMW7Zsqe7du2vr1q3Ffg2WL1+uNm3aqGXLlgoPD1dycrKx7c9//rMeeeQRtWrVSr1799aePXvs3tvdd9+tli1bKjQ0VM8//7wuXbokSVq3bp2eeuopY9+3335bTZs21a5duyRJ+fn5WrhwoRFj7969lZaWJsn+T8WnT5/Wvffea3yGP3+9n3vuOePcFy5c0L333ms33759+9SnTx/9/ve/V58+fbRv3z5jW3Z2tsaPH6+2bdvq/vvv14gRIyTJ+Ho2b95cISEhxme6adMmY97r169Lkv7973+radOmevPNN4v8TNetW6emTZtq2bJlxtjnn39e6Jjt27crIiJCoaGh6tu3rw4dOiRJiouLM+Zv2rSp7rvvPrVs2VJDhgyRJA0YMEAzZ87U448/rlatWum5554r9O+muFiTk5PVvn17I4b4+Hj1799f165dk3TjF9Gfv06XL1/Www8/bPfZltVtt92mp59+Ws2bNy/T/kePHtWAAQMUGhqqHj16aNu2bZKkLVu22P37bt68ufG6KJ9//rm6d++uli1bql27dnrnnXeMbf/4xz/02GOPqXXr1ho+fLgyMjIKHf/tt9+qTZs2ys/PN8a2bt2q8PBwSWX7mbV69Wp16NBBUVFRhc7/v5//li1bjGOK8re//U0tW7bU+PHjFRAQIEm6/fbbNXPmTJJbwEEkuDDNe++9p6SkJL3//vv68ssvVatWLcXFxdnt8/XXX2v//v3av3+/unXrZrft57tI79mzR/v371doaKixbcGCBfr222+1ceNGbdq0Sd99953mz59vbA8ICND+/fu1Z88eBQcHa+7cuca29u3b65NPPtHu3bvVrFkzI8GSbiSEFotFO3bsKDKmoly/fl1jxoxRo0aN9Morr5RpHklKSEjQiBEjjIT85+0LFy7U/v37lZiYaPcZ/fzZNWjQQB988IH27t2rkSNH6pVXXlFmZmaRsXXq1Ekff/yx9u3bp379+mnGjBnGtubNm2vDhg3617/+pbCwMI0ZM8ZIhCSpW7du2r9/vz777DOdOnVKGzZsKHT+7Oxsvffee3b/M166dKk2b96sxYsXa9++fXrjjTdUrVq1QsfOnj1bvr6+hcZPnTplvJ+NGzfa/ek7Oztbzz77rAYMGKDk5GT96U9/0rPPPqvz589LkqKjo3X16lVt3rxZu3bt0qBBgyT993toypQpuu+++4zvuaLaaOLj4xUYGFjk5/mzhg0bav369cbr1atX64477jBep6Sk6NVXX1VcXJySk5P15JNPasSIEcrNzdWkSZOM+X9+j/v379eSJUuM4zds2KA33nhDO3bsUJUqVfTnP/+5yDhKinXx4sXavXu3Fi5cqKpVqxba/s477zhcgSyLvLw8DR8+XG3atNGuXbv02muv6eWXX9axY8fUvXt347MIDQ0t9Nn8rwkTJiguLs749/Hggw9Kknbv3q2ZM2fqrbfe0o4dO1SvXj2NHTu20PEtWrTQLbfcoq+++soYS0hIMBLcsv7M2rJli11yXdz7nj17turUqVPsPrt371aXLl1KPA+A34YEF6ZZuXKlXnzxRdWtW1fe3t4aOXKkPvnkE6P6VJrc3FxZLJYi+9ASEhL0/PPPq3bt2vL399fzzz+vTZs2FdqvoKBA+fn5donU448/rpo1a8rb21ujRo3SoUOHdPHiRWO7zWZTQUFBmWK02Wx69dVXdeXKFU2ZMsVuW2nzdOjQQffff7+8vb314osv6ptvvjEqnSXp1q2bAgMDZbFY1L17dzVs2FD//ve/i9y3QYMGuvXWW41YmzVrZmyLiIiQn5+fqlSposGDBys3N1fHjx8vdI78/HwVFBQUmYwuWrRIffr0MeaQbiR7Y8aM0e233y4PDw8FBwfLz8/P7rhDhw7pm2++Ua9evQqdMzIy0kgeN2zYoMjISGPbZ599poYNGyoyMlJVqlRRWFiYbr/9dm3fvl2ZmZn64osvNGXKFNWqVUteXl5q3bp18R9kEbZv3y6bzVZqq03t2rVVr1497d+/X2fPnjWq0T9btWqVnnzySbVo0UKenp7q1auXvLy89M0335QpjoiICDVp0kTVq1fXmDFj9PHHH9tVHUuLdfXq1Xr33Xe1ZMkS1axZs9D2M2fOaM2aNfrTn/5UaiwPPvigQkNDFRoaWmpSV5Rvv/1WV65c0bBhw+Tt7a2HHnpIHTt21ObNm3/1uapUqaLvv/9ely5dUq1atXT33XdLuvHzoE+fPrr77rvl7e2tsWPH6ptvvtGpU6cKnaNHjx7GL4+XLl3SF198oR49ekgq28+sUaNGqXr16kX+0vZLq1atUosWLdS4ceNi98nOzi4xAQbw29GDC9OcPn1azz//vCyW//4eZbFYdO7cuTIdf+HChWL/TJeZmamgoCDjdVBQkF0VMzMzU6Ghobp27Zpq1aqld999V9KNZO3NN9/Uxx9/rKysLCO28+fP69Zbb9XgwYM1ceJEtWrVSjVr1tRPP/2kZ599ttgYk5KSdOeddyotLU1ZWVnG/6xKm0eS6tata5ynRo0aqlWrljIzM2W1Wkv8XDZs2KClS5caLQ1XrlwxKphFWbx4sebOnatbbrlFr7/+ujH+zjvvaM2aNcrMzJSHh4cuXbpkd56PP/5Yn332ma5cuaLmzZurY8eOdudNTU3VRx99pMTERG3cuNEYT09P1+9+97sS38Nf//pXjRkzRkePHi20LSIiQoMGDdKDDz4oq9Wq2267zdj2v1936cbXPiMjQ+np6apVq5Zq1apV4tzFKSgo0KxZszR16lStXLmy1P2feOIJrV69Wo0bN1ZERIQOHjxobDt9+rQ2bNig999/3xjLy8srttL+v375PRAUFKS8vDy7r01JsWZlZWn+/Pm65ZZbdPDgQbVt27bQ+efOnav+/fuX6bP66quvHKr0ZmZmqm7dunY/B37+mv1af/vb37RgwQLNnDlTTZs21UsvvaSWLVsqMzPTSHalG/+efH19lZGRUejit/DwcPXt21dTpkzR1q1b1axZM9WrV09S2X5m/fLfbXEuXbqkJUuW6IMPPlBMTEyx+/n6+urMmTNlfv8Ayo4KLkxTt25dvf3229qzZ4/x+O6770r98+/PTpw4UWz1IyAgQKdPnzZep6WlGT1sP2/fs2eP/v3vf+ull17SqFGjJN2o9Gzbtk1Lly7V3r179c9//lPSf9sh/P39FRoaqvbt22vPnj3q2rVriTE2aNBAK1as0OOPP25XwS1tHulGIvizy5cv68KFC3bvoSipqal67bXXNHHiRCUnJ2vPnj266667Sjxm2LBh+vbbbzV9+nS98MILysnJ0Z49e7RkyRK99dZb+vrrr7Vnzx7deuutdvF17dpVe/bs0TfffKMmTZrYtTdIN1oMhgwZUqhCWLduXZ08ebLYeL766itlZ2cX2/7h6+uru+66S5MmTdITTzxht+1/v+7Sja99YGCg6tatqwsXLignJ6fEz6M469evV+PGjXXfffeVaf/27dtr37592rBhgyIiIuy2Wa1WDR8+3O57/9tvv1VYWFiZzv3LSn5aWpq8vLzsquAlxerp6am3335bcXFxmjRpktE7/bPjx49rx44dRfaQmiEgIEDp6el2fxX5+Wv2a917771asGCBdu3apUcffVQvvPCCMcfPv/BJN37py87OLnKOO++8U0FBQfriiy+UmJho9zUpy88sDw+PUuN855131K1bNyNxLs5DDz2kTz/9tNTzAfj1SHBhmqeeekpvvfWW8T+erKwsJSUllenYtLQ0rVixQp07dy5ye48ePbRgwQJlZWUpKytL8+bNM/rofsnDw0MWi8W4UOTy5cvy9vaWn5+frl69qlmzZtntf+rUKb399tuKjY0tU5zBwcGqUaOGRo4cqWPHjmnLli1lmke6ccHMnj17lJubq9mzZ6tFixalVm+vXr0qDw8P+fv7S5LWrl1rd/Ha//r++++NP6/+9NNPslgsqlq1qi5fvixPT0/5+/vr+vXrmjt3bqFE6GcWi0UeHh7Kysoyxk6ePKlvv/1WTz75ZKH9n3jiCc2ePVsnTpyQzWbToUOH7KqPc+bM0SuvvFJiojBo0CA1a9ZM7dq1sxt/5JFHdOLECSUkJOj69evasmWLvv/+e3Xo0EEBAQFq3769pkyZogsXLigvL09ff/11sXP8r4ULFxbZt1kcT09PDR06VD179izUvvHEE09o5cqV+vbbb2Wz2XTlyhV99tlnxX7G/2vTpk36/vvvdfXqVc2ePVtdunSxa9UpKdZatWrpzjvvVLt27fTggw/aXfgo3ehff/7554vsy/01rl27ZlzYmZuba9e//Uv33nuvqlWrpiVLligvL0/Jycn65z//qe7du/+q+XJzc7Vp0yZdvHhRXl5eqlGjhlFpDQsL07p163Tw4EHl5uZq1qxZuvfee4tduiwsLEzLly/X119/bfdLrCM/s352+fJlrVu3TsOHDy9139GjR2v//v2aMWOGUcn94Ycf9PLLL//mX9QA3ECLAkwzcOBA2Ww2DR48WJmZmapdu7a6d++uRx99tNRjn3nmGbVt29a4SOh/jRgxQpcvXzYuEuratatxxbx048+iP1+JXbduXeNP85GRkdqxY4fatWsnX19fjRkzRn//+9+N42JjYzVs2LBSKy//y9vbW9OmTdPzzz+vBx98sNR5pBv/k503b56++eYbNWvWrFAiUpQ777xTgwcPVt++feXh4aHIyEi1atWq2P3fe+89ffTRR7p+/boaNGigt956S1WrVlXbtm3Vrl07denSRdWrV1dUVFSh5Pqjjz7Stm3bZLFY1LRpU02dOtXYdvbsWb322mvy8vIqNOef/vQn5ebmavDgwTp//rxuv/12zZs3z9jerFkzPfDAAyW+zxYtWqhFixaFxv38/LRw4UK98cYbmjx5sho2bKiFCxcaCX98fLymTZumbt26KS8vTw888IDuv//+Euf6WYcOHdSoUaMy7fuzPn36FDnevHlzTZ06VXFxcfrhhx9UrVo1tWrVyu5CyZJEREQoJiZGx44dU+vWrTV58uTfFOv48eMVFham5ORk4zP38/Oz62v+rX7Zc/xzNf7w4cOF9vP29tbChQs1ZcoULVq0SIGBgYqPj7e7KK+sNm7cqKlTpyo/P1+NGzc2/s08/PDDGjNmjEaNGqWcnBy1bNmy2FUwpBv/9mbNmqX27dsb3zuSYz+zfnbp0iU999xzZWr/+N3vfqeVK1fqrbfeUlhYmK5fv6569eqpd+/eqlGjRpnnBFCYh+2Xf5MEcFPExMQoMDBQL774orNDgYsZMGCAevbsWag9AwBQdrQoAAAAwK2Q4AIAAMCt0KIAAAAAt0IFFwAAAG6FBBcAAABupUIvEzagYW9nhwAXdJducXYIcEFDG5wufSdUOh+e/HVLAqJyeOnk+6XvZLK8s8dMOa/Xbbebcl5XQwUXAAAAbqVCV3ABAADcUkG+syOo0EhwAQAAXI2twNkRVGi0KAAAAMCtUMEFAABwNQVUcB1BBRcAAABuhQouAACAi7HRg+sQElwAAABXQ4uCQ2hRAAAAgFuhggsAAOBqXLBF4fjx44qJiVF2drZ8fX01Y8YMNWrUyG6f6OhoHT582Hh9+PBhzZs3T507d9acOXP04YcfKiAgQJLUqlUrxcbGSpIGDRqk8+fPS5Ly8/N15MgRbdy4UcHBwYqJidGuXbvk5+cnSeratauee+65EmMlwQUAAECpYmNj1a9fP0VERGjjxo2aNGmSVqxYYbdPfHy88fzQoUOKiopSu3btjLHIyEiNGzeu0LmXLVtmPE9KStJbb72l4OBgY2zYsGHq379/mWOlRQEAAMDVFOSb8/iNzp07p5SUFIWFhUmSwsLClJKSoqysrGKPWbNmjcLDw+Xt7f2r5lqzZo369Onzm2OVSHABAAAqjZycHJ06darQIycnp8Tj0tLSFBgYKE9PT0mSp6enAgIClJaWVuT+ubm5SkhIKJSobt68WeHh4Ro8eLD2799f6LgzZ85o9+7dioiIsBtfunSpwsPDNWLECB09erTU90mLAgAAgKsxqQd3+fLlmjt3bqHxkSNHatSoUeU2T1JSkoKCghQSEmKM9e3bV8OHD5eXl5d27typESNGaMuWLUZvrSRt2LBB7dq1k7+/vzH24osvqk6dOrJYLNqwYYOGDBmipKQkI9kuCgkuAACAqzFpmbCoqCj16tWr0LiPj0+Jx1mtVmVkZCg/P1+enp7Kz89XZmamrFZrkfuvXbu2UPW2Tp06xvM2bdrIarXqyJEjat26tTG+bt06RUdH2x0XGBhoPI+MjNS0adOUnp6uevXqFRsvLQoAAACVhI+Pj+rXr1/oUVqCW7t2bYWEhCgxMVGSlJiYqJCQELtK68/S09O1d+9ehYeH241nZGQYzw8ePKjU1FQ1btzYGNu3b58uXryo9u3bF3vcl19+KYvFYpf0FoUKLgAAgItxxTuZTZ48WTExMZo/f758fHw0Y8YMSdLQoUM1evRoNW/eXJK0fv16dezYUbVq1bI7ftasWTpw4IAsFou8vLwUHx9vV9Vdt26dIiMjC7UejBs3TufOnZOHh4dq1qypBQsWqEqVklNYD5vNZiuPN+0MAxr2dnYIcEF36RZnhwAXNLTBaWeHABf04cni/8SJyuulk+87OwRdO/qVKeeteseDppzX1VDBBQAAcDXcqtchJLgAAACuxgVbFCoSp15ktnPnTmdODwAAADfk1AR3woQJzpweAADANbnYncwqGtNbFH55T+JfstlsunjxotnTAwAAoJIxvYL73nvvqWrVqqpevbrdo0aNGvLw8DB7egAAgIrHVmDOo5IwvYLbpEkTdenSRcHBwYW2rV692uzpAQAAKh5WUXCI6RXcsWPHqkaNGkVumzVrltnTAwAAoJIxvYLbpk2bYrf9/ve/N3t6AACAiqcStROY4aasg3v69Gl9/PHHSktLkyRZrVZ16dJF9epxBxkAAACUL9NbFFavXq2nnnpKqampCgwMVGBgoFJTU/X000/TgwsAAFCUggJzHpWE6RXcJUuWaP369fL397cbf/7559W3b1898cQTZocAAABQodhslWfNWjOYXsEtKCgolNxKkp+fn2w2m9nTAwAAoJIxvYLbtm1bDRkyRH/84x8VFBQk6UZP7j/+8Y8SL0ADAACotLjIzCGmJ7gTJ07Upk2btHbtWp0+fVqSFBQUpB49eigiIsLs6QEAAFDJmJ7gWiwWRUZGKjIy0uypAAAA3EMluiDMDKb34JbkwIEDzpweAAAAbsipCe7s2bOdOT0AAIBrshWY86gkbsqNHiTp/PnzSk9PlyTVrVtXfn5+Wrx48c2aHgAAoOIoYJkwR5ie4J48eVITJ05USkqKAgICJEmZmZlq1qyZ4uLi1LBhQ7NDAAAAQCVieoIbHR2tfv36aenSpbJYbnREFBQUKCEhQdHR0Vq1apXZIQAAAFQslaidwAym9+BmZ2erZ8+eRnIr3VhZISIiQhcuXDB7egAAAFQypie4vr6+SkxMtLtrmc1m06ZNm+Tj42P29AAAABVPQYE5j0rC9BaF6dOnKzY2VnFxcQoMDJQkZWRkKDg4WNOnTzd7egAAgIqHFgWHmJ7gNmrUSMuXL1dWVpbS0tIkSVarVf7+/mZPDQAAgEropi0T5u/vT1ILAABQFpWoncAMTr3RAwAAAFDebloFFwAAAGVEBdchJLgAAAAuxmbjTmaOoEUBAAAAboUKLgAAgKuhRcEhVHABAADgVqjgAgAAuBpu9OAQKrgAAABwK1RwAQAAXA09uA4hwQUAAHA1tCg4hBYFAAAAuBUquAAAAK6GFgWHUMEFAACAW6GCCwAA4GrowXUICS4AAICroUXBIbQoAAAAwK1QwQUAAHA1VHAdUqET3Oaq7uwQ4IJGrwp3dghwQXnvL3d2CHBBI99+xtkhABXG8ePHFRMTo+zsbPn6+mrGjBlq1KiR3T7R0dE6fPiw8frw4cOaN2+eOnfurDlz5ujDDz9UQECAJKlVq1aKjY2VJMXExGjXrl3y8/OTJHXt2lXPPfecJOns2bOKjo5WamqqqlatqqlTp6pFixYlxlqhE1wAAAC35IIXmcXGxqpfv36KiIjQxo0bNWnSJK1YscJun/j4eOP5oUOHFBUVpXbt2hljkZGRGjduXJHnHzZsmPr3719ofObMmQoNDdW7776rPXv26JVXXtEnn3wiDw+PYmOlBxcAAMDVFBSY8/iNzp07p5SUFIWFhUmSwsLClJKSoqysrGKPWbNmjcLDw+Xt7f2b55Wkjz/+WH379pUkhYaGytvbW999912Jx5DgAgAAVBI5OTk6depUoUdOTk6Jx6WlpSkwMFCenp6SJE9PTwUEBCgtLa3I/XNzc5WQkKA+ffrYjW/evFnh4eEaPHiw9u/fb7dt6dKlCg8P14gRI3T06FFJ0vnz52Wz2eTv72/sZ7ValZ6eXmK8tCgAAAC4GpNaFJYvX665c+cWGh85cqRGjRpVbvMkJSUpKChIISEhxljfvn01fPhweXl5aefOnRoxYoS2bNkiPz8/vfjii6pTp44sFos2bNigIUOGKCkp6TfPT4ILAABQSURFRalXr16Fxn18fEo8zmq1KiMjQ/n5+fL09FR+fr4yMzNltVqL3H/t2rWFqrd16tQxnrdp00ZWq1VHjhxR69atFRgYaGyLjIzUtGnTlJ6ernr16kmSsrKyjCpuWlqa6tatW2K8tCgAAAC4GpN6cH18fFS/fv1Cj9IS3Nq1ayskJESJiYmSpMTERIWEhNi1DvwsPT1de/fuVXi4/apGGRkZxvODBw8qNTVVjRs3LrTtyy+/lMViMZLerl27auXKlZKkPXv26KefftI999xTYrxUcAEAAFCqyZMnKyYmRvPnz5ePj49mzJghSRo6dKhGjx6t5s2bS5LWr1+vjh07qlatWnbHz5o1SwcOHJDFYpGXl5fi4+ONqu64ceN07tw5eXh4qGbNmlqwYIGqVLmRpr700kt65ZVXtGHDBlWtWlXx8fGyWEqu0XrYbDZbeX8AN0t8w8JLSQCsg4uisA4uiuL9/CvODgEuqGpIR2eHoKvr3jDlvLf0ftWU87oaKrgAAACuhjuZOYQeXAAAALgVKrgAAACuhgquQ6jgAgAAwK1QwQUAAHA1FXcNAJdAggsAAOBqaFFwCC0KAAAAcCtUcAEAAFwNFVyHUMEFAACAW6GCCwAA4GpsVHAdQYILAADgamhRcAgtCgAAAHArVHABAABcDevgOoQKLgAAANwKFVwAAABXQw+uQ6jgAgAAwK04NcHduXOnM6cHAABwTQUF5jwqCacmuBMmTHDm9AAAAK7JVmDOo5IwvQc3Pj6+yHGbzaaLFy+aPT0AAAAqGdMruO+9956qVq2q6tWr2z1q1KghDw8Ps6cHAACocGwFNlMelYXpFdwmTZqoS5cuCg4OLrRt9erVZk8PAACASsb0BHfs2LGqUaNGkdtmzZpl9vQAAAAVTyW6IMwMpie4bdq0KXbb73//e7OnBwAAqHgq0QVhZnDqKgoHDhxw5vQAAABwQ05NcGfPnu3M6QEAAFxTgc2cRyVx027Ve/78eaWnp0uS6tatKz8/Py1evPhmTQ8AAIBKwvQE9+TJk5o4caJSUlIUEBAgScrMzFSzZs0UFxenhg0bmh0CAABAxcJFZg4xPcGNjo5Wv379tHTpUlksNzoiCgoKlJCQoOjoaK1atcrsEAAAACoWElyHmN6Dm52drZ49exrJrSRZLBZFRETowoULZk8PAACASsb0BNfX11eJiYmy2f7b2Gyz2bRp0yb5+PiYPT0AAEDFY7OZ86gkTG9RmD59umJjYxUXF6fAwEBJUkZGhoKDgzV9+nSzpwcAAEAlY3qC26hRIy1fvlxZWVlKS0uTJFmtVvn7+5s9NQAAQMVED65DbtoyYf7+/iS1AAAAMN1NS3ABAABQRpXopgxmIMEFAABwNTZaFBzh1Fv1AgAAAOWNCi4AAICroUXBIVRwAQAA4Fao4AIAALgYG8uEOYQEFwAAwNXQouAQWhQAAADgVqjgAgAAuBqWCXMIFVwAAAC4FSq4AAAArsYFe3CPHz+umJgYZWdny9fXVzNmzFCjRo3s9omOjtbhw4eN14cPH9a8efPUuXNnzZkzRx9++KECAgIkSa1atVJsbKwkacqUKdq9e7e8vb1VvXp1TZgwQc2bN5ckDRgwQKdPn1bNmjUlSQMHDlSfPn1KjJUEFwAAwNW44CoKsbGx6tevnyIiIrRx40ZNmjRJK1assNsnPj7eeH7o0CFFRUWpXbt2xlhkZKTGjRtX6Nzt27fXq6++Ki8vL23fvl0vvviikpKSjO2vvfaaOnbsWOZYaVEAAABAic6dO6eUlBSFhYVJksLCwpSSkqKsrKxij1mzZo3Cw8Pl7e1d6vk7duwoLy8vSdJ9992n9PR0FTiQ5FPBBQAAcDUmtSjk5OQoJyen0LiPj498fHyKPS4tLU2BgYHy9PSUJHl6eiogIEBpaWny9/cvtH9ubq4SEhK0bNkyu/HNmzdrx44dqlOnjkaNGqWWLVsWOvaDDz5Qhw4dZLH8tw4bHx+vWbNmqWnTpnrllVcUGBhY4vskwQUAAKgkli9frrlz5xYaHzlypEaNGlVu8yQlJSkoKEghISHGWN++fTV8+HB5eXlp586dGjFihLZs2SI/Pz9jn82bNyshIUEffPCBMRYfHy+r1ar8/HwtWrRIL7zwgv7+97+XOD8JLgAAgKsxaZmwqKgo9erVq9B4SdVbSbJarcrIyFB+fr48PT2Vn5+vzMxMWa3WIvdfu3ZtoQvB6tSpYzxv06aNrFarjhw5otatW0uStm7dqjfffFPLli3TbbfdZje3dKNqPHDgQM2dO1cFBQV2Fd7/RQ8uAABAJeHj46P69esXepSW4NauXVshISFKTEyUJCUmJiokJKTI9oT09HTt3btX4eHhduMZGRnG84MHDyo1NVWNGzeWJG3fvl3Tpk3TO++8o/r16xv7Xb9+XWfPnjVeb968WU2aNCkxuZWo4AIAALgeF1wmbPLkyYqJidH8+fPl4+OjGTNmSJKGDh2q0aNHG8t6rV+/Xh07dlStWrXsjp81a5YOHDggi8UiLy8vxcfHG1Xd8ePHy8vLS6NHjzb2X7ZsmapWraphw4YpLy9PkhQQEKBZs2aVGquHzWZzvU+wjOIb9nd2CHBBo1eFl74TKp2895c7OwS4IO/nX3F2CHBBVUPKvhyVWS6NL3md19+q5rS1ppzX1dCiAAAAALdSoVsU/uPxk7NDgAuy5V51dghwQQUXrzk7BLggj1oBzg4BKJoLtihUJFRwAQAA4FYqdAUXAADALVHBdQgJLgAAgKsxaR3cyoIWBQAAALgVKrgAAACuhhYFh1DBBQAAgFuhggsAAOBibFRwHUKCCwAA4GpIcB1CiwIAAADcChVcAAAAV1PAMmGOoIILAAAAt0IFFwAAwNXQg+sQKrgAAABwK1RwAQAAXA0VXIeQ4AIAALgYm40E1xG0KAAAAMCtUMEFAABwNbQoOIQKLgAAANwKFVwAAABXQwXXISS4AAAALsZGgusQWhQAAADgVqjgAgAAuBoquA6hggsAAAC3QgUXAADA1RQ4O4CK7aYkuP/5z3/k4eGhu+66SydOnNBnn32mJk2a6OGHH74Z0wMAAFQoXGTmGNMT3Pfee09Lly7V9evX9cwzz2jjxo1q3ry5Vq5cqQEDBujpp582OwQAAABUIqYnuKtXr1ZiYqKuXLmizp0765NPPlHdunWVlZWlwYMHk+ACAAD8Lyq4DjE9wbVYLKpevbqqV6+uBg0aqG7dupIkf39/eXh4mD09AAAAKhnTE9yCgv92SY8dO9ZuW15entnTAwAAVDxcZOYQ05cJGzRokC5fvixJ6tSpkzF+9OhRtWnTxuzpAQAAUMmYXsHt3bt3keN33HGHxo8fb/b0AAAAFQ6rKDjGqTd6OHDggDOnBwAAcE0FJj0qCacmuLNnz3bm9AAAAHBDN+1OZufPn1d6erokqW7duvLz89PixYtv1vQAAAAVBi0KjjE9wT158qQmTpyolJQUBQQESJIyMzPVrFkzxcXFqWHDhmaHAAAAgErE9AQ3Ojpa/fr109KlS2Wx3OiIKCgoUEJCgqKjo7Vq1SqzQwAAAKhYKlG/rBlM78HNzs5Wz549jeRWunHzh4iICF24cMHs6QEAACocW4E5j8rC9ATX19dXiYmJstn+20tis9m0adMm+fj4mD09AAAAKhnTWxSmT5+u2NhYxcXFKTAwUJKUkZGh4OBgTZ8+3ezpAQAAKp5KVG01g+kJbqNGjbR8+XJlZWUpLS1NkmS1WuXv72/21AAAAKiEbtoyYf7+/iS1AAAAZVCZ+mXNcNMSXAAAAJQRCa5DSHABAABQquPHjysmJkbZ2dny9fXVjBkz1KhRI7t9oqOjdfjwYeP14cOHNW/ePHXu3Flz5szRhx9+aNwXoVWrVoqNjZUkXb16VePHj9eBAwfk6empcePGqWPHjqVuKw4JLgAAgItxxRaF2NhY9evXTxEREdq4caMmTZqkFStW2O0THx9vPD906JCioqLUrl07YywyMlLjxo0rdO533nlHNWvW1NatW3XixAk9/fTT+vTTT1WjRo0StxXH9GXCAAAA4BpycnJ06tSpQo+cnJwSjzt37pxSUlIUFhYmSQoLC1NKSoqysrKKPWbNmjUKDw+Xt7d3qXF99NFHevLJJyXdWKDgnnvu0RdffFHqtuJQwQUAAHAxZlVwly9frrlz5xYaHzlypEaNGlXscWlpaQoMDJSnp6ckydPTUwEBAUpLSytyEYHc3FwlJCRo2bJlduObN2/Wjh07VKdOHY0aNUotW7aUJJ0+fVr16tUz9rNarUpPTy91W3FIcAEAAFyMWQluVFSUevXqVWi8vG++lZSUpKCgIIWEhBhjffv21fDhw+Xl5aWdO3dqxIgR2rJli/z8/Mp1bokWBQAAgErDx8dH9evXL/QoLcG1Wq3KyMhQfn6+JCk/P1+ZmZmyWq1F7r927Vr16dPHbqxOnTry8vKSJLVp00ZWq1VHjhyRJAUFBSk1NdXYNy0tTXXr1i11W3FIcAEAAFyNzcOcx29Uu3ZthYSEKDExUZKUmJiokJCQItsT0tPTtXfvXoWHh9uNZ2RkGM8PHjyo1NRUNW7cWJLUtWtXrVq1SpJ04sQJfffdd8bFaSVtKw4tCgAAACjV5MmTFRMTo/nz58vHx0czZsyQJA0dOlSjR49W8+bNJUnr169Xx44dVatWLbvjZ82apQMHDshiscjLy0vx8fGqU6eOJOmZZ55RTEyMHnvsMVksFsXFxalmzZqlbiuOh81ms5X3B3CzDGn0uLNDgAuasyLM2SHABeW+856zQ4ALumXa35wdAlyQd9Ddzg5B6e07mHLeul98Zsp5XQ0tCgAAAHArtCgAAAC4GFvBb++XBQkuAACAy3HFO5lVJLQoAAAAwK1QwQUAAHAxNgeW9AIVXAAAALgZKrgAAAAuhh5cx5DgAgAAuBhWUXAMLQoAAABwK1RwAQAAXEzFvc+sa6jQCe431zKcHQJcUMGX/3R2CHBB105dd3YIcEFV0486OwS4Ihe4VS8cU6ETXAAAAHdED65jSHABAABcDAmuY7jIDAAAAG6FCi4AAICL4SIzx1DBBQAAgFuhggsAAOBi6MF1DBVcAAAAuJVSE1ybzaZLly4Vue3SpUuy0SQCAABQrmw2D1MelUWpCe7y5cs1efLkIrdNmTJF7733XnnHBAAAUKnZCsx5VBalJrjr16/XyJEji9w2cuRIrVu3rtyDAgAAAH6rUi8yO336tBo1alTktoYNGyo1NbW8YwIAAKjUCipRO4EZSq3genp66uzZs0VuO3v2rCwWrlMDAACA6yg1O33ggQf0zjvvFLlt6dKlevDBB8s9KAAAgMqMi8wcU2qLwgsvvKAnn3xSx48fV5cuXVSnTh2dOXNGn3zyifbv369Vq1bdjDgBAAAqDdbBdUypCW7jxo21Zs0azZkzRzNnzlR2drZ8fX310EMPac2aNWrQoMHNiBMAAAAokzLdyex3v/ud/vKXv5S63+LFizVs2DCHgwIAAKjMuM2AY8r1CrGFCxeW5+kAAACAX61MFdyy4q5mAAAAjqMH1zHlmuB6ePDFAAAAcBTr4DqGRWwBAADgVmhRAAAAcDGVac1aM5RrBTc0NLQ8TwcAAAD8ar+qgpuamqpDhw7pypUrduPh4eGSpLfffrv8IgMAAKik+KO4Y8qc4C5atEjz58/XHXfcoWrVqhnjHh4eRoILAAAAOFuZE9x3331Xa9eu1Z133unQhBcuXNCRI0fUuHFj1a5d26FzAQAAuCNWUXBMmXtwfX19Va9evV89wdSpU43n33zzjbp166Y33nhDPXr00JdffvmrzwcAAODubDYPUx6VRZkruK+++qomTpyoqKioQpXXoKCgYo/bt2+f8XzOnDn661//qocfflgHDx7UpEmT1K5du98QNgAAAFC0Mie4eXl52rlzpxITE+3GPTw8dPDgwTKd4+zZs3r44YclSSEhIcrNzf0VoQIAAFQOXGTmmDInuFOmTNHYsWPVvXt3u4vMSpORkaH4+HjZbDZduHBB+fn58vT0lCQVFBT8+ogBAACAEpQ5wc3Pz1fv3r2N5LSs+vXrZzx//PHHlZ2drdq1aysjI0N33333rzoXAABAZcBFZo4pc4I7ePBgLV68WMOHD5eHR9k/9JEjRxY5HhgYqOnTp5f5PAAAAJVFZbogzAxlTnDfe+89nT17VosWLZKvr6/dts8+++w3TX7gwAGquAAAAChXZU5w//KXv5T75LNnz9bixYvL/bwAAAAVmSu2KBw/flwxMTHKzs6Wr6+vZsyYoUaNGtntEx0drcOHDxuvDx8+rHnz5qlz587G2LFjx9SrVy/169dP48aNkyQNGjRI58+fl3SjLfbIkSPauHGjgoODFRMTo127dsnPz0+S1LVrVz333HMlxlrmBLd169Zl3bVI58+fV3p6uiSpbt268vPzI7kFAACoIGJjY9WvXz9FRERo48aNmjRpklasWGG3T3x8vPH80KFDioqKslsSNj8/X7GxsXr00Uftjlu2bJnxPCkpSW+99ZaCg4ONsWHDhql///5ljrXMCa4kHTx4UHv27NH58+dl+8X6FWPGjCn2mJMnT2rixIlKSUlRQECAJCkzM1PNmjVTXFycGjZs+GtCAAAAcHuutkrYuXPnlJKSoqVLl0qSwsLCNHXqVGVlZcnf37/IY9asWaPw8HB5e3sbY4sXL1aHDh105coVXblypdjj+vTp41C8Zb6T2apVq/TUU0/pq6++0ttvv63//Oc/Wrp0qU6ePFnicdHR0erTp4+Sk5O1efNmbd68WcnJyerdu7eio6MdCh4AAMAdFdg8THnk5OTo1KlThR45OTklxpOWlqbAwEBjNS1PT08FBAQoLS2tyP1zc3OVkJBgl6geOnRIO3bs0KBBg4qd58yZM9q9e7ciIiLsxpcuXarw8HCNGDFCR48eLfXzK3MFd8mSJVqyZIlCQ0N1//33a968efr888+1ZcuWEo/Lzs5Wz5497cYsFosiIiK0YMGCsk4PAAAABy1fvlxz584tND5y5EiNGjWq3OZJSkpSUFCQQkJCJN24YdjEiRM1bdq0Epec3bBhg9q1a2dXFX7xxRdVp04dWSwWbdiwQUOGDFFSUlKJ5ylzgnvu3DmFhoZKupGgFhQU6JFHHtErr7xS4nG+vr5KTExUjx49jOXFbDabEhIS5OPjU9bpAQAAKg2zlgmLiopSr169Co2XlpNZrVZlZGQYN+zKz89XZmamrFZrkfuvXbvWrnp75swZnTx5UsOGDZMk5eTkyGaz6dKlS5o6daqx37p16wr9hT8wMNB4HhkZqWnTpik9PV316tUrNt4yJ7h169bVqVOnVL9+fTVq1Ejbtm2Tn5+fvLy8Sjxu+vTpio2NVVxcnBFgRkaGgoODWQcXAADgJvLx8flNBcbatWsrJCREiYmJioiIUGJiokJCQorsv01PT9fevXs1a9YsYywoKEjJycnG6zlz5ujKlSvGKgqStG/fPl28eFHt27e3O19GRoaRQ3755ZeyWCx2SW9RypzgDhkyREePHlX9+vU1YsQIjRkzRnl5eZowYUKJxzVq1EjLly9XVlaW0adhtVqLbUgGAACo7AqcHUARJk+erJiYGM2fP18+Pj6aMWOGJGno0KEaPXq0mjdvLklav369OnbsqFq1av2q869bt06RkZGFWg/GjRunc+fOycPDQzVr1tSCBQtUpUrJKayH7ZfLIRTDZrPp1KlTslqtxglzc3OVl5enGjVq/Krgy1OotV3pO6HS+XxkY2eHABd0+Z8/ODsEuCCfv7zk7BDggqq16ln6Tib7su7jppy3XfoaU87rasq0ioKHh4fCw8Nlsfx3d29vb6cmtwAAAO7KJg9THpVFmZcJCwkJ0fHjx82MBQAAAJIKbOY8KotfdSezoUOHqlevXqpbt66xIoIkPf64OWV0AAAA4Ncqc4K7b98+1atXT//617/sxj08PEhwAQAAylFBJWonMEOZE9z33nvPzDgAAACAclHmBPeXbDabfrn4wi8vPgMAAIBjKtMFYWYoc4KbkZGhuLg47dmzp9D9ig8ePFjugQEAAFRWrrgObkVS5tJrbGysvLy8tGzZMlWvXl3r169Xp06dNGXKFDPjAwAAAH6VMldw9+/fr+3bt6t69ery8PBQcHCwXn/9dfXt21d//OMfzYwRAACgUqFFwTFlruBaLBbjLmY+Pj7KyspS9erVlZGRYVpwAAAAwK9V5gpuixYt9Pnnn+uxxx5T27Zt9cILL6hatWq65557zIwPAACg0qEH1zFlTnDj4+ONlRMmTJigd955R1euXNHAgQNNCw4AAKAyIsF1TJkT3GrVqmnBggXavHmzMjMzFRAQoG7duqlWrVpmxgcAAAD8KmVOcCdPnqzjx49rwoQJqlevnlJTU7Vo0SJNnjxZ06ZNMzNGAACASoWLzBxT5gR327Zt2rp1q3x8fCRJd955p1q0aKE//OEPpgUHAAAA/FplTnBvu+02Xb161UhwJenatWuqU6eOKYEBAABUVgUUcB1S5gQ3IiJCQ4YM0YABAxQYGKj09HR98MEHioiI0O7du439HnroIVMCBQAAAMqizAnuypUrJUkLFy4sNP7zNg8PD23btq0cwwMAAKh8CujBdUiZE9x//vOfZsYBAACA/8/m7AAquDLfyQwAAACoCMpcwXVFl/J/cnYIcEGp72c6OwS4oEuXfJ0dAlzQPXUaOjsEoEjc6MExVHABAADgVip0BRcAAMAdFXhwkZkjSHABAABcDBeZOYYWBQAAALgVKrgAAAAuhovMHEMFFwAAAG6FCi4AAICLKeAaM4eQ4AIAALgYbtXrGFoUAAAA4Fao4AIAALgYlglzDBVcAAAAuBUquAAAAC6Gi8wcQwUXAAAAboUKLgAAgIvhRg+OIcEFAABwMVxk5hhaFAAAAOBWqOACAAC4GC4ycwwVXAAAALgVKrgAAAAuhovMHEOCCwAA4GJIcB1DiwIAAADcChVcAAAAF2PjIjOHUMEFAABAqY4fP64nn3xSXbp00ZNPPqkTJ04U2ic6OloRERHGIzg4WNu2bbPb59ixY2rRooVmzJhhjMXExKh9+/bGcQsWLDC2nT17VoMHD1aXLl3Us2dPffvtt6XGSgUXAADAxbhiD25sbKz69euniIgIbdy4UZMmTdKKFSvs9omPjzeeHzp0SFFRUWrXrp0xlp+fr9jYWD366KOFzj9s2DD179+/0PjMmTMVGhqqd999V3v27NErr7yiTz75RB4exZe5Ta/gbt++XXl5eWZPAwAA4DYKTHr8VufOnVNKSorCwsIkSWFhYUpJSVFWVlaxx6xZs0bh4eHy9vY2xhYvXqwOHTqoUaNGZZ77448/Vt++fSVJoaGh8vb21nfffVfiMaYnuCNGjFC7du30+uuv69ChQ2ZPBwAAgGLk5OTo1KlThR45OTklHpeWlqbAwEB5enpKkjw9PRUQEKC0tLQi98/NzVVCQoL69OljjB06dEg7duzQoEGDijxm6dKlCg8P14gRI3T06FFJ0vnz52Wz2eTv72/sZ7ValZ6eXmK8prcoNG3aVNOnT9eaNWs0aNAgBQUFqU+fPurZs6duvfVWs6cHAACocGwmnXf58uWaO3duofGRI0dq1KhR5TZPUlKSgoKCFBISIknKy8vTxIkTNW3aNCNJ/qUXX3xRderUkcVi0YYNGzRkyBAlJSX95vlNT3A9PDwUHBys1157TePGjdPWrVu1bt06/fWvf1WnTp00c+ZMs0MAAACApKioKPXq1avQuI+PT4nHWa1WZWRkKD8/X56ensrPz1dmZqasVmuR+69du9auenvmzBmdPHlSw4YNk3Sjkmyz2XTp0iVNnTpVgYGBxr6RkZGaNm2a0tPTVa9ePUlSVlaWUcVNS0tT3bp1S4zX9ATXZvvv7yBeXl7q3r27unfvrvT0dG3YsMHs6QEAACqcApOWCfPx8Sk1mS1K7dq1FRISosTEREVERCgxMVEhISF2rQM/S09P1969ezVr1ixjLCgoSMnJycbrOXPm6MqVKxo3bpwkKSMjw0hyv/zyS1ksFuN1165dtXLlSo0YMUJ79uzRTz/9pHvuuafEeG9Ki0JR6tatq+HDh5s9PQAAAMrB5MmTFRMTo/nz58vHx8dY5mvo0KEaPXq0mjdvLklav369OnbsqFq1apX53OPGjdO5c+fk4eGhmjVrasGCBapS5Uaa+tJLL+mVV17Rhg0bVLVqVcXHx8tiKfkyMg/bL0usFUxwwP3ODgEuaFPt2s4OAS7o0qWqzg4BLuieXXHODgEuyLtBC2eHoDd/V3i5rPLw4sn3TTmvq3HqjR4OHDjgzOkBAABckqstE1bRODXBnT17tjOnBwAAgBu6aXcyO3/+vLFmWd26deXn56fFixffrOkBAAAqjArbP+oiTE9wT548qYkTJyolJUUBAQGSpMzMTDVr1kxxcXFq2LCh2SEAAACgEjE9wY2Ojla/fv20dOlS44q3goICJSQkKDo6WqtWrTI7BAAAgArFrGXCKgvTe3Czs7PVs2dPu+UcLBaLIiIidOHCBbOnBwAAqHC4yMwxpie4vr6+SkxMtLvhg81m06ZNm37TQsMAAABASUxvUZg+fbpiY2MVFxdn3JEiIyNDwcHBmj59utnTAwAAVDhcZOYY0xPcRo0aafny5crKylJaWpqkG/czLurWbgAAAICjbtoyYf7+/iS1AAAAZVBADdchNy3BBQAAQNlUpgvCzODUO5kBAAAA5Y0KLgAAgIuhQcExVHABAADgVqjgAgAAuBh6cB1DBRcAAABuhQouAACAiynwcHYEFRsJLgAAgIthHVzH0KIAAAAAt0IFFwAAwMVQv3UMFVwAAAC4FSq4AAAALoZlwhxDggsAAOBiuMjMMbQoAAAAwK1QwQUAAHAx1G8dQwUXAAAAboUKLgAAgIvhIjPHkOACAAC4GC4ycwwtCgAAAHArVHABAABcDPVbx1DBBQAAgFup0BXc77NPOzsEuKDTHo2cHQJckI93rrNDgAvyuOVWZ4cAFImLzBxToRNcAAAAd2SjScEhtCgAAADArVDBBQAAcDG0KDiGCi4AAADcChVcAAAAF8ONHhxDBRcAAABuhQouAACAi6F+6xgSXAAAABdDi4JjaFEAAACAW6GCCwAA4GJYJswxVHABAADgVqjgAgAAuBhXvFXv8ePHFRMTo+zsbPn6+mrGjBlq1KiR3T7R0dE6fPiw8frw4cOaN2+eOnfubIwdO3ZMvXr1Ur9+/TRu3DhJ0pQpU7R79255e3urevXqmjBhgpo3by5JGjBggE6fPq2aNWtKkgYOHKg+ffqUGCsJLgAAgItxxRaF2NhY9evXTxEREdq4caMmTZqkFStW2O0THx9vPD906JCioqLUrl07Yyw/P1+xsbF69NFH7Y5r3769Xn31VXl5eWn79u168cUXlZSUZGx/7bXX1LFjxzLHSosCAAAASnTu3DmlpKQoLCxMkhQWFqaUlBRlZWUVe8yaNWsUHh4ub29vY2zx4sXq0KFDocpvx44d5eXlJUm67777lJ6eroKC357mk+ACAAC4GJtJ/+Xk5OjUqVOFHjk5OSXGk5aWpsDAQHl6ekqSPD09FRAQoLS0tCL3z83NVUJCgl0rwaFDh7Rjxw4NGjSoxLk++OADdejQQRbLf9PU+Ph4hYeH6+WXX1ZGRkapnx8tCgAAAJXE8uXLNXfu3ELjI0eO1KhRo8ptnqSkJAUFBSkkJESSlJeXp4kTJ2ratGlGklyUzZs3KyEhQR988IExFh8fL6vVqvz8fC1atEgvvPCC/v73v5c4PwkuAACAizGrBzcqKkq9evUqNO7j41PicVarVRkZGcrPz5enp6fy8/OVmZkpq9Va5P5r1661q96eOXNGJ0+e1LBhwyRJOTk5stlsunTpkqZOnSpJ2rp1q958800tW7ZMt912m93c0o2q8cCBAzV37lwVFBTYVXj/FwkuAACAiymwmbOKgo+PT6nJbFFq166tkJAQJSYmKiIiQomJiQoJCZG/v3+hfdPT07V3717NmjXLGAsKClJycrLxes6cObpy5YqxisL27ds1bdo0LV26VPXr1zf2u379urKzs42Ed/PmzWrSpEmJya1EggsAAIAymDx5smJiYjR//nz5+PhoxowZkqShQ4dq9OjRxrJe69evV8eOHVWrVq0yn3v8+PHy8vLS6NGjjbFly5apatWqGjZsmPLy8iRJAQEBdolzcTxsNpN+RbgJqnjXc3YIcEFJfg87OwS4IB/vXGeHABfUfP+bzg4BLsjrttudHYL6N+xtynnf/2GdKed1NayiAAAAALdCiwIAAICLKXDBO5lVJFRwAQAA4Fao4AIAALgYGxVch9yUBDcjI0MfffSRUlNTVaVKFd1xxx0KDw9X1apVb8b0AAAAFYpZ6+BWFqa3KGzatEl9+/ZVcnKyEhISlJGRoU8//VRdu3bV4cOHzZ4eAAAAlYzpFdxFixZp7dq18vf3148//qg33nhDixcv1u7duxUXF2d3KzYAAABwkZmjTK/genp6Gne5aNCggdLS0iRJDz30kM6fP2/29AAAAKhkTK/g1q9fXwsWLFC7du20efNm3XXXXZKk/Px85efnmz09AABAhcNFZo4xvYIbFxen77//XjExMTp//rzGjx8vSbp48aImTJhg9vQAAAAVToFJj8rC9ArubbfdppkzZxYa9/X1Vfv27c2eHgAAAJWMU2/0cODAAWdODwAA4JJsNpspj8rCqQnu7NmznTk9AAAA3NBNu5PZ+fPnlZ6eLkmqW7eu/Pz8tHjx4ps1PQAAQIXBMmGOMT3BPXnypCZOnKiUlBQFBARIkjIzM9WsWTPFxcWpYcOGZocAAABQoVSmC8LMYHqCGx0drX79+mnp0qWyWG50RBQUFCghIUHR0dFatWqV2SEAAACgEjG9Bzc7O1s9e/Y0kltJslgsioiI0IULF8yeHgAAoMKxmfRfZWF6guvr66vExES7K/dsNps2bdokHx8fs6cHAABAJWN6i8L06dMVGxuruLg4BQYGSpIyMjIUHBys6dOnmz09AABAhcNFZo4xPcFt1KiRli9frqysLKWlpUmSrFar/P39zZ4aAAAAldBNWybM39+fpBYAAKAMKtNNGcxw0xJcAAAAlA3LhDnGqXcyAwAAAMobFVwAAAAXU5mW9DIDFVwAAAC4FSq4AAAALoZlwhxDggsAAOBiWEXBMbQoAAAAwK1QwQUAAHAxtCg4hgouAAAA3AoVXAAAABfDMmGOIcEFAABwMQVcZOYQWhQAAADgVqjgAgAAuBjqt46hggsAAAC3QgUXAADAxbBMmGOo4AIAAMCtUMEFAABwMVRwHUOCCwAA4GJsLBPmEFoUAAAA4Fao4AIAALgYWhQcQ4ILt3OySlVnhwAXdI9ynR0CXFDBhUxnhwBXdNvtzo4ADiLBBQAAcDE2KrgOoQcXAADAxdhsNlMejjh+/LiefPJJdenSRU8++aROnDhRaJ/o6GhFREQYj+DgYG3bts1un2PHjqlFixaaMWOGMXb16lW98MILeuyxx9S1a1dt3769TNuKQwUXAAAApYqNjVW/fv0UERGhjRs3atKkSVqxYoXdPvHx8cbzQ4cOKSoqSu3atTPG8vPzFRsbq0cffdTuuHfeeUc1a9bU1q1bdeLECT399NP69NNPVaNGjRK3FYcKLgAAgIspkM2Ux2917tw5paSkKCwsTJIUFhamlJQUZWVlFXvMmjVrFB4eLm9vb2Ns8eLF6tChgxo1amS370cffaQnn3xSktSoUSPdc889+uKLL0rdVhwSXAAAgEoiJydHp06dKvTIyckp8bi0tDQFBgbK09NTkuTp6amAgAClpaUVuX9ubq4SEhLUp08fY+zQoUPasWOHBg0aVGj/06dPq169esZrq9Wq9PT0UrcVhxYFAAAAF2PWjR6WL1+uuXPnFhofOXKkRo0aVW7zJCUlKSgoSCEhIZKkvLw8TZw4UdOmTTOSZDOR4AIAALgYs9bBjYqKUq9evQqN+/j4lHic1WpVRkaG8vPz5enpqfz8fGVmZspqtRa5/9q1a+2qt2fOnNHJkyc1bNgwSTcqyTabTZcuXdLUqVMVFBSk1NRU+fv7S7pRMX7ggQckqcRtxSHBBQAAqCR8fHxKTWaLUrt2bYWEhCgxMVERERFKTExUSEiIkXT+Unp6uvbu3atZs2YZY0FBQUpOTjZez5kzR1euXNG4ceMkSV27dtWqVavUvHlznThxQt99951mzpxZ6rbi0IMLAADgYmwm/eeIyZMn6/3331eXLl30/vvva8qUKZKkoUOH6rvvvjP2W79+vTp27KhatWqV+dzPPPOMcnJy9Nhjj+nZZ59VXFycatasWeq24njYzGryuAmqeNcrfSdUOu/W6ejsEOCC7rFcdHYIcEF3fzbe2SHABVW940Fnh6B76z5kynn/nb7blPO6GloUAAAAXExBxa0/ugRaFAAAAOBWqOACAAC4GEf7ZSs7ElwAAAAXQ4uCY2hRAAAAgFuhggsAAOBiaFFwDBVcAAAAuBUquAAAAC6GHlzHkOACAAC4GFoUHEOLAgAAANwKFVwAAAAXQ4uCY6jgAgAAwK1QwQUAAHAx9OA6hgQXAADAxdhsBc4OoUKjRQEAAABu5aZUcE+fPq2PP/5YaWlpkiSr1aouXbqoXr16N2N6AACACqWAFgWHmF7BXb16tZ566imlpqYqMDBQgYGBSk1N1dNPP63Vq1ebPT0AAAAqGdMruEuWLNH69evl7+9vN/7888+rb9++euKJJ8wOAQAAoEKxsUyYQ0yv4BYUFBRKbiXJz8+PLx4AAADKnekV3LZt22rIkCH64x//qKCgIEk3enL/8Y9/qE2bNmZPDwAAUOHQg+sY0xPciRMnatOmTVq7dq1Onz4tSQoKClKPHj0UERFh9vQAAAAVDn/ldozpCa7FYlFkZKQiIyPNngoAAABw7jq4Bw4ccOb0AAAALqnAZjPlUVk4NcGdPXu2M6cHAACAG3LqrXoXL17szOkBAABcko2LzBzi1ApueHi4M6cHAABwSTabzZRHZWF6Bff7778vdtv58+fNnh4AAACVjOkJblhYmOrVq1fkbw3Z2dlmTw8AAFDhsA6uY0xPcOvVq6cPP/xQgYGBhbY98sgjZk8PAACASsb0Htw//OEPSk1NLXLbY489Zvb0AAAAFQ49uI4xvYI7bty4Yre99tprZk8PAABQ4VSmNWvN4NRVFAAAAIDy5tR1cAEAAFBYZWonMAMVXAAAALgVKrgAAAAuhmXCHEMFFwAAAG6FCi4AAICLoQfXMSS4AAAALoZlwhxDiwIAAADcChVcAAAAF2PjIjOHUMEFAACAW6GCCwAA4GLowXUMCS4AAICLYRUFx9CiAAAAALdCBRcAAMDFuOJFZsePH1dMTIyys7Pl6+urGTNmqFGjRnb7REdH6/Dhw8brw4cPa968eercubPWrl2rZcuWyWKxqKCgQE888YQGDhxY6nFz5szRhx9+qICAAElSq1atFBsbW2KsHrYKXAOv4l3P2SHABb1bp6OzQ4ALusdy0dkhwAXd/dl4Z4cAF1T1jgedHYKqVmtgynmv/fTjbz524MCB6tOnjyIiIrRx40atXbtWK1asKHb/Q4cOKSoqSl9++aW8vb116dIl1ahRQx4eHrp06ZLCw8O1YMECBQcHl3jcnDlzdOXKFY0bN67MsVLBBQAAcDFm1R9zcnKUk5NTaNzHx0c+Pj7FHnfu3DmlpKRo6dKlkqSwsDBNnTpVWVlZ8vf3L/KYNWvWKDw8XN7e3pKkmjVrGtt++ukn5eXlycPDo9TjfgsSXAAAABdjVoK7fPlyzZ07t9D4yJEjNWrUqGKPS0tLU2BgoDw9PSVJnp6eCggIUFpaWpEJbm5urhISErRs2TK78W3btmnWrFk6efKkXnrpJTVt2rRMx23evFk7duxQnTp1NGrUKLVs2bLE90mCCwAAUElERUWpV69ehcZLqt7+FklJSQoKClJISIjdeOfOndW5c2edPn1azz//vNq3b6/bb7+9xOP69u2r4cOHy8vLSzt37tSIESO0ZcsW+fn5FTs/CS4AAICLMesCqdJaEYpjtVqVkZGh/Px8eXp6Kj8/X5mZmbJarUXuv3btWvXp06fY8wUFBal58+b67LPP7BLcoo6rU6eO8bxNmzayWq06cuSIWrduXez5WSYMAAAAJapdu7ZCQkKUmJgoSUpMTFRISEiR7Qnp6enau3evwsPD7caPHj1qPM/KylJycrKaNGlS6nEZGRnG84MHDyo1NVWNGzcuMd4KXcG9npvq7BAAAADKnSvmOJMnT1ZMTIzmz58vHx8fzZgxQ5I0dOhQjR49Ws2bN5ckrV+/Xh07dlStWrXsjl+1apV27typKlWqyGazqX///mrbtq2xvbjjZs2apQMHDshiscjLy0vx8fF2Vd2iVOhlwgAAAID/RYsCAAAA3AoJLgAAANwKCS4AAADcCgkuAAAA3AoJLgAAANwKCS4AAADcCgkuAAAA3AoJLgAAANwKCS4AAADcCgkuAAAA3AoJLgAAANwKCa6Latq0qS5fvixJ6tSpk/7zn/8Uud++ffsUFhamyMhIffXVVzczRJSzX37Nhw4dqpMnT0qSBgwYoO3btxd5zC+3zZ49W1u2bLk5wQIA4MKqODsAOGbjxo2KjIzUkCFDnB0KytHbb7/9q48ZM2aMCZEU7fr166pShR8fAADXxP+hKohNmzZp165dunjxoqKiotS/f38tWbJEH330kapVq6aEhAStWrVK//d//6cpU6ZIkh544AFt27ZNixYt0p133qm4uDh99dVX8vb2VvXq1bVy5UonvysUp1OnTlq4cKGaNGkiSdq1a5fmzZunCxcuqFu3bho7dmyhY2JiYnTPPfeof//+mjNnjo4fP66LFy/qxx9/1O9+9zvNnj1bt9xyi3Jzc/Xmm2/q66+/Vm5urpo2barJkyerRo0aSkhI0IoVK5SXlydJGjdunB566CEjpu7du+urr75SkyZN9MYbb9y8DwRldvXqVY0bN07ff/+9qlSposaNG+u1117T2LFjdfnyZV27dk2PPPKIoqOjJUkXL17Uq6++qiNHjigwMFCBgYGqXbu2xo0b5+R3AkeU5/fB7t279dZbb+natWvKz8/X8OHD1aNHDye/Q6BkJLgVxLlz57Ru3TqdPXtWkZGRCg0N1ZAhQ/T9998bSU1ubq7Gjh2rWbNmKTQ0VFu3btV7770nSTp06JCSk5O1ZcsWWSwWXbhwwcnvCL/G0aNHtXLlSl27dk19+/ZVy5Yt1bFjxxKP+b//+z+tWbNGt956q5555hklJCToj3/8o5YsWaJbb71Va9askST95S9/0eLFi/Xiiy+qbdu2CgsLk4eHh44dO6ZBgwbpiy++MM556dIl4zi4ph07dujy5ctGu8qFCxdUrVo1LVy4UDVq1FBeXp6eeeYZffHFF2rfvr3mzZsnHx8fffzxx8rOzlbv3r3VpUsXJ78LOKo8vw+aNWumDz/8UJ6enjp79qx69+6ttm3bqlatWs58i0CJSHAriMcff1ySdNttt6lDhw7617/+peDgYLt9jh07pmrVqik0NFSS9Nhjj8nHx0eS1KBBA12/fl0TJkzQAw88UGpyBNcSGRmpKlWqqEqVKkYVtbSvYdu2bY2v/7333mv09P7zn//UpUuX9Mknn0iScnNzje+lH3/8US+99JIyMjJUpUoVnT17VmfOnFGdOnWMOODagoODdfToUU2ZMkWtW7dWhw4dlJ+fr/j4eO3fv182m01nz57VoUOH1L59eyUnJ+u1116TJPn6+urRRx918jtAeSjP74OsrCy9+uqr+uGHH+Tp6akLFy7o+PHjuu+++5z07oDSkeBWErfeeqs2b96s5ORk7dq1S3/961+1fv16I3GB+6latarx3NPTU9euXZMk2Ww2xcbGGq0HvzR27FjFxMTo0UcfVUFBgVq0aGEcJ0nVq1c3P3A4pEGDBkpMTNRXX32lL774Qm+++aYiIiKUk5Oj1atXq2rVqpo4caLd1xXupzy/DyZPnqxOnTpp7ty58vDwUJcuXfj+gctjFYUKYv369ZJu/Cb9+eef64EHHii0z+23366rV69q7969kqSkpCTl5OQYx129elXt2rXTyy+/rFtvvVU//vjjzXsDcMimTZt0/fp1XblyRR999JEefPDB33yuTp06admyZfrpp58k3Wg7OHr0qKQbfXj169eXJK1du1a5ubmOB4+bKj09XZ6ennr00Uc1fvx4ZWVl6dSpU6pTp46qVq2qjIwMbdu2zdi/devW2rhxoyQpJyfHbhsqrvL8Prh48aLq1asnDw8P7dy5Uz/88MNNfz/Ar0UFt4Lw8/NT7969dfHiRT377LNq2rRpoX28vb01c+ZMTZ48WdKNH1i1a9fWrbfeqrS0NE2cOFHXr19Xfn6+2rdvz5+XKpDbb79dffv2NS4yc6TFZNiwYZo7d64ef/xxeXh4yMPDQyNHjtQdd9yh8ePHa8SIEapVq5batWsnX1/f8nsTuCkOHz6smTNnSpIKCgo0bNgw9ejRQ2PGjFFYWJgCAwPtqvfPP/+8xo8fr65du6pOnTq65557VLNmTWeFj3JSnt8HL730kqZMmaI5c+aoefPmRf7/B3A1HjabzebsIFB+Ll26ZPxQ+uqrrzR+/Hht27ZNFgvFegCF5eXlqaCgQFWrVtWlS5f01FNPafz48Xr44YedHRpuIr4P4G6o4LqZTz/9VMuWLZPNZpO3t7f++te/ktwCKFZOTo6GDh2q/Px8Xbt2TWFhYSQ1lRDfB3A3VHABAADgVijtAQAAwK2Q4AIAAMCtkOACAADArZDgAsCv0KlTJ+3atcvZYQAASkCCCwAAALdCggvAZdhsNhUUFDg7jJvu+vXrzg4BANwKCS6ActGpUyctWrRI3bt31/3336/x48fr2rVrunDhgp599lk9+OCDuv/++/Xss88qPT3dOG7AgAF688031bdvX7Vo0UI//vij1q5dq27duqlly5bq3LmzVq5caeyfnJys9u3b6+2339ZDDz2ktm3bKikpSZ9//rm6dOmi1q1ba+HChaXG++9//1u9e/dWq1at9PDDD2vatGnGtm3btqlHjx4KDQ3VgAEDjFsZ/1JGRobuvfdeZWdnG2MpKSl64IEHlJeXJ0las2aNunXrpvvvv1/PPPOMUlNTjX2bNm2qDz74QH/4wx/0hz/84Vd91gCAkpHgAig3CQkJeuedd7R161YdP35c8+fPV0FBgXr37q3t27dr+/btqlq1quLi4uyO27hxo6ZOnap9+/YpKChItWvX1qJFi7Rv3z5NmzZN06ZN04EDB4z9z549q2vXrumLL77Q6NGj9dprr2nTpk1au3atPvjgA82fP18//vhjibG+/vrrGjhwoPbt26etW7eqW7dukqTjx4/rpZde0quvvqrdu3erffv2Gj58uHJzc+2ODwwM1H333adPP/3U7v136dJFXl5eSkpK0qJFizR37lzt3r1bv//97/XSSy/ZnSMpKUn/+Mc/tGXLlt/0eQMAikaCC6DcPP3007JarfL19dVzzz2nzZs3y8/PT126dNEtt9yimjVr6rnnntPXX39td1yvXr101113qUqVKvLy8lKHDh30u9/9Th4eHmrdurXatGmjPXv2GPtXqVJFzz33nLy8vNS9e3edP39eAwcOVM2aNXXXXXfpzjvv1OHDh0uMtUqVKjp58qSysrJUo0YN3XfffZKkLVu26JFHHlGbNm3k5eWlZ555Rj/99JP2799f6Bzh4eFKTEyUdKO9YsuWLQoPD5ckrVy5UsOGDdMdd9yhKlWqaPjw4Tp48KBdFXfYsGHy9fVVtWrVftPnDQAoGrfqBVBurFar8TwoKEiZmZm6evWqpk2bpi+//FIXLlyQJF2+fFn5+fny9PQsdJwkff7555o3b55OnDihgoIC/fTTT2rSpImx3dfX1zj25+Swdu3axvaqVavq8uXLJcb6+uuv629/+5u6deum+vXra+TIkerYsaMyMzMVFBRk7GexWGS1WpWRkVHoHH/4wx80depUZWZm6sSJE7JYLAoNDZUknT59Wm+88YZmzJhh7G+z2ZSRkaF69eoV+b4BAOWDBBdAuUlLSzOenz59WgEBAXr33Xd1/Phx/eMf/1CdOnV08OBBRUZG6pd3Cffw8DCe5+bmavTo0ZoxY4Y6d+4sLy8vjRgxQuV9V/FGjRpp1qxZKigo0KeffqrRo0crOTlZAQEB+s9//mPsZ7PZlJaWpsDAwELnqFWrltq0aaMtW7bo2LFj6t69u/FerFarhg8frp49exYbwy/fNwCg/NCiAKDcfPjhh0pPT1d2drYWLlyo7t276/Lly6patap8fHyUnZ2tuXPnlniO3Nxc5ebmyt/fX1WqVNHnn3+unTt3lnusGzduVFZWliwWi3x8fCTdqNZ269ZNn3/+uXbv3q28vDy9++678vb2VsuWLYs8T3h4uDZu3KhPPvnEaE+QpL59+2rx4sU6cuSIJOnixYv66KOPyv19AAAKo4ILoNyEhYVp8ODByszMVOfOnfXcc88pJydHL7/8sh588EEFBAToT3/6k5KSkoo9R82aNfXaa6/phRdeUG5urjp27KhOnTqVe6xffvmlpk+frp9++klBQUF68803Va1aNd1+++36y1/+oqlTpyojI0MhISFauHChvL29izxPp06dNGHCBAUFBSk4ONgYf+yxx3T58mWNHTtWqampuvXWW/Xwww8bF7MBAMzjYSvvv/sBqJQ6deqkP//5z3r44YedHQoAoJKjRQEAAABuhRYFAG5ryJAh2rt3b6HxZ599VsOHD3dCRACAm4EWBQAAALgVWhQAAADgVkhwAQAA4FZIcAEAAOBWSHABAADgVkhwAQAA4FZIcAEAAOBW/h9tXdsesL/5WgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Отрисуем, как менялась точность при различных гиперпараметрах\n",
        "visual = pd.pivot_table(pd.DataFrame(grid_search_lr.cv_results_),\n",
        "                        values='mean_test_score', index='param_C',\n",
        "                        columns='param_solver')\n",
        "sns.heatmap(visual)\n",
        "plt.title('Тепловая карта зависимости метрики F1 от solver и С') # подпись графика\n",
        "sns.set(rc={'figure.figsize':(12, 8)}) #задаем размер графика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg4WA9JH1Sg5"
      },
      "source": [
        "Видим, что слабая регуляризация С = 0,01 отрицательно влияет на метрику, поэтому есть смысл брать значения больше 0,05 и  алгоритмы оптимизации: _liblinear_, _sag_ и _saga_ возможно отработают лучше. К сожалению, не отработал алгоритм _lbfgs_ из-за превышения количества итераций, возможно есть смысл заменить его на другой алгоритм, т.к. по условиям задания увеличивать количество итераций нельзя."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ_Tkna7YLzm"
      },
      "source": [
        "## 2.2. Подбор гиперпараметров для алгоритма **Случайный лес** методом **GridSearchCV** (**GSCV**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkaYBqY_YCDJ",
        "outputId": "50282427-2914-478f-f10d-cee7c3662c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 30.3 s, sys: 2.87 s, total: 33.2 s\n",
            "Wall time: 1h 39s\n",
            "f1_score на обучающем наборе: 0.99\n",
            "f1_score на тестовом наборе: 0.83\n",
            "Наилучшие значения гиперпараметров: {'max_depth': 20, 'min_samples_leaf': 2, 'n_estimators': 140}\n"
          ]
        }
      ],
      "source": [
        "# Создадим словарь искомых гиперпараметров\n",
        "param_grid_rf = {'n_estimators': list(range(80, 200, 10)),\n",
        "              'min_samples_leaf': list(range(2, 10, 1)),\n",
        "              'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
        "              }\n",
        "            \n",
        "# Вызываем класс GridSearchCV и передаем модель RandomForestClassifier и прочие данные для расчетов,\n",
        "grid_search_rf = GridSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
        "    param_grid=param_grid_rf, \n",
        "    cv=5, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "\n",
        "%%time\n",
        "\n",
        "grid_search_rf.fit(X_train, y_train) \n",
        "y_train_pred = grid_search_rf.predict(X_train)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "y_test_pred = grid_search_rf.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_rf.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtEYXMICnKgZ"
      },
      "source": [
        "Для **Случайного леса** получены следующие значения _F1-score_ при подборе гиперпараметров методом GridSearchCV на: обучающем наборе - 0.99, на тестовом наборе - 0.83. Удалось улучшить метрику случайный лес с помощью **GSCV** со 0.81 до 0.83."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1k2GWwgn61r"
      },
      "source": [
        "## 2.3. Подбор гиперпараметров для алгоритма **Логистической регрессии** методом **RandomizedSearchCV** (**RSCV**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjrirlJFnxrd",
        "outputId": "7d45c083-757c-4c23-e8e1-497ec748f198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 11.4 µs\n",
            "f1_score на обучающем наборе: 0.87\n",
            "f1_score на тестовом наборе: 0.79\n",
            "Наилучшие значения гиперпараметров: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.23}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV # импортируем RandomizedSearchCV\n",
        "\n",
        "# Создадим словарь искомых гиперпараметров\n",
        "param_distributions_lr = [\n",
        "              {'penalty': ['l2', None] , # тип регуляризации\n",
        "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
        "               'C': list(np.linspace(0.01, 1, 10, dtype=float))}, # уровень силы регурялизации\n",
        "              \n",
        "              {'penalty': ['l1', 'l2'] ,\n",
        "              'solver': ['liblinear', 'saga'],\n",
        "               'C': list(np.linspace(0.01, 1, 10, dtype=float))}\n",
        "                ]\n",
        "\n",
        "# Вызываем класс RandomizedSearchCV и передаем модель LogisticRegression и прочие данные для расчетов            \n",
        "random_search_lr = RandomizedSearchCV(\n",
        "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=50), \n",
        "    param_distributions=param_distributions_lr, \n",
        "    cv=5, \n",
        "    n_iter = 10, \n",
        "    n_jobs = -1\n",
        "    )  \n",
        "\n",
        "%%time\n",
        "\n",
        "random_search_lr.fit(X_train, y_train) \n",
        "y_train_pred = random_search_lr.predict(X_train)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "y_test_pred = random_search_lr.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_lr.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fAFXZu1p-2k"
      },
      "source": [
        "Для **Логистической регрессии** получены следующие значения _F1-score_ при подборе гиперпараметров методом RandomizedSearchCV на: обучающем наборе - 0.87, тестовом наборе - 0.79. Улучшить метрику логистической регрессии с помощью **RSCV** не удалось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj24iqttqZUJ"
      },
      "source": [
        "## 2.4. Подбор гиперпараметров для алгоритма **Случайный лес** методом **RandomizedSearchCV** (**RSCV**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKUPI8FDqta3",
        "outputId": "4bbd428d-8973-49d6-d875-c0a9814c3046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6.78 s, sys: 401 ms, total: 7.18 s\n",
            "Wall time: 6min 32s\n",
            "f1_score на обучающем наборе: 0.99\n",
            "f1_score на тестовом наборе: 0.83\n",
            "Наилучшие значения гиперпараметров: {'n_estimators': 160, 'min_samples_leaf': 2, 'max_depth': 20}\n"
          ]
        }
      ],
      "source": [
        "# Создадим словарь искомых гиперпараметров\n",
        "param_distributions_rf = {'n_estimators': list(range(80, 200, 10)),\n",
        "              'min_samples_leaf': list(range(2, 10, 1)),\n",
        "              'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
        "              }\n",
        "\n",
        "# Вызываем класс GridSearchCV и передаем модель RandomForestClassifier и прочие данные для расчетов,            \n",
        "random_search_rf = RandomizedSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
        "    param_distributions=param_distributions_rf, \n",
        "    cv=5,\n",
        "    n_iter = 50, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "\n",
        "%%time\n",
        "\n",
        "random_search_rf.fit(X_train, y_train) \n",
        "y_train_pred = random_search_rf.predict(X_train)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "y_test_pred = random_search_rf.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_rf.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItsoUKGQtaHo"
      },
      "source": [
        "Для **Случайного леса** получены следующие значения _F1-score_ при подборе гиперпараметров методом RandomizedSearchCV на: обучающем наборе - 0.99, тестовом наборе: 0.83. Улучшить метрику случайного леса с помощью **RSCV** не удалось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LoFuWu0v3EU"
      },
      "source": [
        "# 3. Подбор гиперпараметров с помощью продвинутых методов оптимизации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo8KLD_eZjfE"
      },
      "source": [
        "## 3.1. Подбор гиперпараметров для алгоритма **Логистическая регрессия** методом **Hyperopt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU481H9VwzsX",
        "outputId": "00b1aa95-54e6-47e8-c84e-7932b10f6d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.9/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from hyperopt) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.9/dist-packages (from hyperopt) (4.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from hyperopt) (1.22.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from hyperopt) (3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from hyperopt) (4.65.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from pymongo->hyperopt) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Устанавливаем библиотеку\n",
        "%pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1EnF43-wQEq",
        "outputId": "154052bb-8fef-411f-bbb3-e47a15b412d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Версия Hyperopt : 0.2\n"
          ]
        }
      ],
      "source": [
        "#делаем импорт и выведем версию библиотеки\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "# fmin - основная функция, она будет минимизировать наш функционал\n",
        "# tpe - алгоритм оптимизации\n",
        "# hp - включает набор методов для объявления пространства поиска гиперпараметров\n",
        "# trails - используется для логирования результатов\n",
        "\n",
        "print(\"Версия Hyperopt : {}\".format(hyperopt.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig4A2_puxU94"
      },
      "outputs": [],
      "source": [
        "# зададим пространство поиска гиперпараметров\n",
        "space_lr= {\n",
        "          'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
        "          'solver': hp.choice('solver', ['liblinear', 'saga']),\n",
        "          'C': hp.quniform('C', 0.1, 1, 0.1)\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p61wv9TLxedk"
      },
      "outputs": [],
      "source": [
        "# зафиксируем random_state\n",
        "random_state = 42\n",
        "def hyperopt_lr(params_lr, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
        "    # функция получает комбинацию гиперпараметров в \"params\"\n",
        "    params_lr = {'penalty': (params_lr['penalty']), \n",
        "              'solver': (params_lr['solver']), \n",
        "              'C': float(params_lr['C'])\n",
        "              }\n",
        "  \n",
        "    # используем эту комбинацию для построения модели\n",
        "    model_lr_ho = linear_model.LogisticRegression(**params_lr, random_state=random_state, max_iter=50)\n",
        "\n",
        "    # обучаем модель\n",
        "    model_lr_ho.fit(X, y)\n",
        "    score = metrics.f1_score(y, model_lr_ho.predict(X))\n",
        "    \n",
        "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
        "    return -score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsPbE84IxoDk",
        "outputId": "ec95ac6e-1daa-459c-ca78-9f2de89def9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 7.63 µs\n",
            "  2%|▏         | 1/50 [00:03<03:00,  3.68s/it, best loss: -0.8634978671541743]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5/50 [00:11<01:59,  2.65s/it, best loss: -0.8823709135349832]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 6/50 [00:17<02:44,  3.74s/it, best loss: -0.8823709135349832]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 11/50 [00:26<01:51,  2.87s/it, best loss: -0.8823709135349832]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 13/50 [00:31<01:49,  2.96s/it, best loss: -0.8823709135349832]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 17/50 [00:38<01:20,  2.44s/it, best loss: -0.8823709135349832]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 19/50 [00:48<02:09,  4.18s/it, best loss: -0.8823709135349832]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 31/50 [01:00<00:38,  2.02s/it, best loss: -0.8856968215158926]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 35/50 [01:06<00:27,  1.83s/it, best loss: -0.8856968215158926]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 39/50 [01:13<00:26,  2.45s/it, best loss: -0.8856968215158926]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 42/50 [01:20<00:21,  2.73s/it, best loss: -0.8856968215158926]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 46/50 [01:29<00:12,  3.06s/it, best loss: -0.8856968215158926]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 49/50 [01:35<00:02,  2.77s/it, best loss: -0.8856968215158926]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:36<00:00,  1.93s/it, best loss: -0.8856968215158926]\n",
            "Наилучшие значения гиперпараметров {'C': 1.0, 'penalty': 1, 'solver': 0}\n"
          ]
        }
      ],
      "source": [
        "# начинаем подбор гиперпараметров\n",
        "trials = Trials() # используется для логирования результатов\n",
        "\n",
        "%%time\n",
        "\n",
        "best = fmin(\n",
        "          hyperopt_lr, # наша функция \n",
        "          space=space_lr, # пространство гиперпараметров\n",
        "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
        "          max_evals=50, # максимальное количество итераций\n",
        "          trials=trials, # логирование результатов\n",
        "          rstate=np.random.RandomState(random_state) # фиксируем для повторяемости результата\n",
        "         )\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8u0kFKocb9V",
        "outputId": "8e88afda-6c40-4aef-eca9-24ddf3b38a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score на обучающем наборе: 0.89\n",
            "f1_score на тестовом наборе: 0.78\n"
          ]
        }
      ],
      "source": [
        "# Рассчитаем точность для тестовой выборки\n",
        "model_lr_ho = linear_model.LogisticRegression(\n",
        "    random_state=random_state, \n",
        "    C= best['C'], \n",
        "    penalty = 'l2', \n",
        "    solver = 'liblinear'\n",
        ")\n",
        "\n",
        "model_lr_ho.fit(X_train, y_train)\n",
        "y_train_pred = model_lr_ho.predict(X_train)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "y_test_pred = model_lr_ho.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHCDBDQYflPu"
      },
      "source": [
        "Для **Логистической регрессии** получены следующие значения _F1-score_ при подборе гиперпараметров методом **Hyperopt** на: обучающем наборе - 0.89, тестовом наборе - 0.78. Улучшить метрику логистической регрессии с помощью **Hyperopt** не удалось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBpgkS7p4Iys"
      },
      "source": [
        "## 3.2. Подбор гиперпараметров для алгоритма **Случайный лес** методом **Hyperopt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k0EQpZz4Sr_"
      },
      "outputs": [],
      "source": [
        "# Зададим пространство поиска гиперпараметров\n",
        "space_rf={'n_estimators': hp.quniform('n_estimators', 80, 200, 10),\n",
        "       'max_depth' : hp.quniform('max_depth', 20, 40, 5),\n",
        "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYFjpDTS4YuK"
      },
      "outputs": [],
      "source": [
        "# Зафиксируем random_state\n",
        "random_state = 42\n",
        "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
        "    # Функция получает комбинацию гиперпараметров в \"params\"\n",
        "    params = {'n_estimators': int(params['n_estimators']), \n",
        "              'max_depth': int(params['max_depth']), \n",
        "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
        "              }\n",
        "  \n",
        "    # Используем эту комбинацию для построения модели\n",
        "    model_rf = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
        "\n",
        "    # Обучаем модель\n",
        "    model_rf.fit(X, y)\n",
        "    score = metrics.f1_score(y, model_rf.predict(X))\n",
        "\n",
        "    # Метрику необходимо минимизировать, поэтому ставим знак минус\n",
        "    return -score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXd1GkzV4hBg",
        "outputId": "1cded9ea-b8fa-46cf-8180-8d47eb93051f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [02:12<00:00,  2.64s/it, best loss: -0.9920294297976702]\n",
            "Наилучшие значения гиперпараметров {'max_depth': 25.0, 'min_samples_leaf': 2.0, 'n_estimators': 140.0}\n"
          ]
        }
      ],
      "source": [
        "# Начинаем подбор гиперпараметров\n",
        "trials = Trials() # используется для логирования результатов\n",
        "\n",
        "%%time\n",
        "\n",
        "best=fmin(hyperopt_rf, # наша функция \n",
        "          space=space_rf, # пространство гиперпараметров\n",
        "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
        "          max_evals=50, # максимальное количество итераций\n",
        "          trials=trials, # логирование результатов\n",
        "          rstate=np.random.RandomState(random_state) # фиксируем для повторяемости результата\n",
        "         )\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2G5sXqLhK1x",
        "outputId": "b536199a-efa6-4979-e0d0-91ddd507fe07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score на обучающем наборе: 0.99\n",
            "f1_score на тестовом наборе: 0.82\n"
          ]
        }
      ],
      "source": [
        "# Рассчитаем точность для тестовой выборки\n",
        "model_rf = ensemble.RandomForestClassifier(\n",
        "    random_state=random_state, \n",
        "    n_estimators=int(best['n_estimators']),\n",
        "    max_depth=int(best['max_depth']),\n",
        "    min_samples_leaf=int(best['min_samples_leaf'])\n",
        ")\n",
        "\n",
        "model_rf.fit(X_train, y_train)\n",
        "y_train_pred = model_rf.predict(X_train)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "y_test_pred = model_rf.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBFHUmodhgUP"
      },
      "source": [
        "Для **Случайного леса** получены следующие значения _F1-score_ при подборе гиперпараметров методом **Hyperopt** на: обучающем наборе - 0.99, тестовом наборе: 0.82. Улучшить метрику с помощью **Hyperopt** случайного леса не удалось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uARb6DW6nAxz"
      },
      "source": [
        "## 3.3. Подбор гиперпараметров для алгоритма **Логистическая регрессия** методом **Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbRTqnGPqDDn",
        "outputId": "cbd80548-abe0-47f1-c82a-2276369a62bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.46)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.2 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n"
          ]
        }
      ],
      "source": [
        "# Устанавливаем библиотеку\n",
        "%pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tg0wLzKp6TT",
        "outputId": "bc7909b2-e1e9-4a1a-b13c-517ffab34d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Версия Optuna: 3.1.0\n"
          ]
        }
      ],
      "source": [
        "# Импортируем  библиотеку\n",
        "import optuna\n",
        "\n",
        "print(\"Версия Optuna: {}\".format(optuna.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tc755dRm7XV"
      },
      "outputs": [],
      "source": [
        "# Настроим оптимизацию гиперпараметров для алгоритма логистической регрессии.\n",
        "def optuna_lr(trial):\n",
        "  # Задаем пространства поиска гиперпараметров\n",
        "  param_lr_opt={'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']), \n",
        "                'solver' : trial.suggest_categorical('solver', ['liblinear', 'saga']), \n",
        "                'C': trial.suggest_float('C', 0.1, 1, step = 0.1)\n",
        "              }\n",
        "  # Создаем модель\n",
        "  model_lr_opt = linear_model.LogisticRegression(**param_lr_opt, random_state=random_state, max_iter=50)\n",
        "  \n",
        "  # Обучаем модель\n",
        "  model_lr_opt.fit(X_train, y_train)\n",
        "  score = metrics.f1_score(y_train, model_lr_opt.predict(X_train))\n",
        "\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pegw1ZqDnbA-",
        "outputId": "14f03e2d-119d-4c40-d131-e0d4875c317d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-03-11 10:06:45,145]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:06:47,673]\u001b[0m Trial 0 finished with value: 0.8681553992046498 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 1.0}. Best is trial 0 with value: 0.8681553992046498.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:06:48,362]\u001b[0m Trial 1 finished with value: 0.8023880597014925 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.1}. Best is trial 0 with value: 0.8681553992046498.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:06:50,201]\u001b[0m Trial 2 finished with value: 0.8604580152671755 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.8}. Best is trial 0 with value: 0.8681553992046498.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:06:51,339]\u001b[0m Trial 3 finished with value: 0.864567410577805 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.9}. Best is trial 0 with value: 0.8681553992046498.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:06:57,423]\u001b[0m Trial 4 finished with value: 0.8340888485947416 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.4}. Best is trial 0 with value: 0.8681553992046498.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:06:58,191]\u001b[0m Trial 5 finished with value: 0.8813455657492353 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:07:02,324]\u001b[0m Trial 6 finished with value: 0.8633181126331811 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.5}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:07:06,226]\u001b[0m Trial 7 finished with value: 0.8629719853836785 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.7000000000000001}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:07:13,630]\u001b[0m Trial 8 finished with value: 0.8471589182619265 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.8}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:07:17,483]\u001b[0m Trial 9 finished with value: 0.8548828719196836 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.2}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:17,990]\u001b[0m Trial 10 finished with value: 0.8756889161053277 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.6}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:18,519]\u001b[0m Trial 11 finished with value: 0.8756889161053277 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.6}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:19,039]\u001b[0m Trial 12 finished with value: 0.870602630773937 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.4}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:19,564]\u001b[0m Trial 13 finished with value: 0.8756889161053277 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.6}. Best is trial 5 with value: 0.8813455657492353.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:20,122]\u001b[0m Trial 14 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:20,702]\u001b[0m Trial 15 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:21,266]\u001b[0m Trial 16 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:21,838]\u001b[0m Trial 17 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:22,400]\u001b[0m Trial 18 finished with value: 0.8823709135349832 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:22,973]\u001b[0m Trial 19 finished with value: 0.8823709135349832 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:23,571]\u001b[0m Trial 20 finished with value: 0.8788249694002448 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.7000000000000001}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:24,145]\u001b[0m Trial 21 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:24,908]\u001b[0m Trial 22 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:25,712]\u001b[0m Trial 23 finished with value: 0.8823709135349832 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:26,551]\u001b[0m Trial 24 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:27,345]\u001b[0m Trial 25 finished with value: 0.8813455657492353 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:07:32,781]\u001b[0m Trial 26 finished with value: 0.8634978671541743 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:33,565]\u001b[0m Trial 27 finished with value: 0.8788249694002448 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.7000000000000001}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:34,355]\u001b[0m Trial 28 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:35,433]\u001b[0m Trial 29 finished with value: 0.8681553992046498 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:35,999]\u001b[0m Trial 30 finished with value: 0.8823709135349832 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:36,567]\u001b[0m Trial 31 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:37,150]\u001b[0m Trial 32 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:37,708]\u001b[0m Trial 33 finished with value: 0.8813455657492353 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:38,522]\u001b[0m Trial 34 finished with value: 0.864567410577805 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:39,563]\u001b[0m Trial 35 finished with value: 0.8681553992046498 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:40,210]\u001b[0m Trial 36 finished with value: 0.8621951219512194 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.2}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:07:45,397]\u001b[0m Trial 37 finished with value: 0.8634978671541743 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:46,074]\u001b[0m Trial 38 finished with value: 0.8604580152671755 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.8}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:46,609]\u001b[0m Trial 39 finished with value: 0.870602630773937 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.4}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:07:50,293]\u001b[0m Trial 40 finished with value: 0.8629719853836785 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.7000000000000001}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:50,864]\u001b[0m Trial 41 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:51,426]\u001b[0m Trial 42 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:51,976]\u001b[0m Trial 43 finished with value: 0.8823709135349832 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:52,545]\u001b[0m Trial 44 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:07:53,116]\u001b[0m Trial 45 finished with value: 0.8813455657492353 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-11 10:08:00,275]\u001b[0m Trial 46 finished with value: 0.8507145028884159 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 1.0}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:08:00,831]\u001b[0m Trial 47 finished with value: 0.8823709135349832 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:08:01,241]\u001b[0m Trial 48 finished with value: 0.8489993935718616 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.1}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 10:08:01,765]\u001b[0m Trial 49 finished with value: 0.8731617647058824 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.5}. Best is trial 14 with value: 0.8856968215158926.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Создаем объект исследования\n",
        "study_lr = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
        "# Ищем лучшую комбинацию гиперпараметров n_trials раз\n",
        "study_lr.optimize(optuna_lr, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCXqhKeqrH2_",
        "outputId": "a472e472-58ea-449b-bdc9-ca0bf9660f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров {'penalty': 'l2', 'solver': 'liblinear', 'C': 1.0}\n",
            "f1_score на обучающем наборе: 0.89\n"
          ]
        }
      ],
      "source": [
        "# Выводим результаты на обучающей выборке\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(study_lr.best_params))\n",
        "print(\"f1_score на обучающем наборе: {:.2f}\".format(study_lr.best_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ys9Mi_BrmXl",
        "outputId": "7ed763c7-6201-42af-a9ce-e8e256770d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score на тестовом наборе: 0.78\n"
          ]
        }
      ],
      "source": [
        "# Рассчитаем точность для тестовой выборки\n",
        "model_lr_opt = linear_model.LogisticRegression(**study_lr.best_params,random_state=random_state, )\n",
        "model_lr_opt.fit(X_train, y_train)\n",
        "y_train_pred = model_lr_opt.predict(X_train)\n",
        "y_test_pred = model_lr_opt.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggGJF_CcDSFU"
      },
      "source": [
        "Для **Логистической регрессии** получены следующие значения _F1-score_ при подборе гиперпараметров методом **Optuna** на: обучающем наборе - 0.89, тестовом наборе - 0.78. Улучшить метрику логистической регрессии с помощью **Optuna** не удалось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fq-W2zmtqmY"
      },
      "source": [
        "## 3.4. Подбор гиперпараметров для алгоритма **Случайный лес** методом **Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh8cRZRXt103"
      },
      "outputs": [],
      "source": [
        "# Настроим оптимизацию гиперпараметров для алгоритма случайного леса.\n",
        "def optuna_rf(trial):\n",
        "  # задаем пространства поиска гиперпараметров\n",
        "  n_estimators = trial.suggest_int('n_estimators', 80, 200, 10)\n",
        "  max_depth = trial.suggest_int('max_depth', 20, 40, 5)\n",
        "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
        "\n",
        "  # создаем модель\n",
        "  model_rf_opt = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
        "                                          max_depth=max_depth,\n",
        "                                          min_samples_leaf=min_samples_leaf,\n",
        "                                          random_state=random_state)\n",
        "  # обучаем модель\n",
        "  model_rf_opt.fit(X_train, y_train)\n",
        "  score = metrics.f1_score(y_train, model_rf_opt.predict(X_train))\n",
        "\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U2EqJdJuLPp",
        "outputId": "19cf264e-8f00-459d-810c-a442fe63cfed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-03-11 08:12:54,544]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:12:57,877]\u001b[0m Trial 0 finished with value: 0.9779546846295162 and parameters: {'n_estimators': 110, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9779546846295162.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:00,425]\u001b[0m Trial 1 finished with value: 0.9593644974029942 and parameters: {'n_estimators': 130, 'max_depth': 40, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9779546846295162.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:03,321]\u001b[0m Trial 2 finished with value: 0.9089798411728772 and parameters: {'n_estimators': 170, 'max_depth': 30, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.9779546846295162.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:07,944]\u001b[0m Trial 3 finished with value: 0.928288068355203 and parameters: {'n_estimators': 190, 'max_depth': 20, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.9779546846295162.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:10,722]\u001b[0m Trial 4 finished with value: 0.9456654456654457 and parameters: {'n_estimators': 120, 'max_depth': 20, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9779546846295162.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:12,737]\u001b[0m Trial 5 finished with value: 0.923640806353085 and parameters: {'n_estimators': 90, 'max_depth': 35, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.9779546846295162.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:14,499]\u001b[0m Trial 6 finished with value: 0.9144254278728606 and parameters: {'n_estimators': 80, 'max_depth': 40, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.9779546846295162.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:16,438]\u001b[0m Trial 7 finished with value: 0.9337423312883436 and parameters: {'n_estimators': 90, 'max_depth': 40, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.9779546846295162.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:18,145]\u001b[0m Trial 8 finished with value: 0.991421568627451 and parameters: {'n_estimators': 80, 'max_depth': 35, 'min_samples_leaf': 2}. Best is trial 8 with value: 0.991421568627451.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:19,370]\u001b[0m Trial 9 finished with value: 0.9005812174977057 and parameters: {'n_estimators': 80, 'max_depth': 40, 'min_samples_leaf': 9}. Best is trial 8 with value: 0.991421568627451.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:23,786]\u001b[0m Trial 10 finished with value: 0.9920343137254902 and parameters: {'n_estimators': 160, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:31,694]\u001b[0m Trial 11 finished with value: 0.9920343137254902 and parameters: {'n_estimators': 160, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:35,222]\u001b[0m Trial 12 finished with value: 0.9920343137254902 and parameters: {'n_estimators': 160, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:39,147]\u001b[0m Trial 13 finished with value: 0.9571603427172583 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:43,591]\u001b[0m Trial 14 finished with value: 0.9926470588235294 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.9926470588235294.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:47,572]\u001b[0m Trial 15 finished with value: 0.9587029672682778 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.9926470588235294.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:52,663]\u001b[0m Trial 16 finished with value: 0.9785670545009185 and parameters: {'n_estimators': 180, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.9926470588235294.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:13:58,128]\u001b[0m Trial 17 finished with value: 0.97796817625459 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.9926470588235294.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:00,885]\u001b[0m Trial 18 finished with value: 0.9435803598658127 and parameters: {'n_estimators': 140, 'max_depth': 20, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.9926470588235294.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:05,811]\u001b[0m Trial 19 finished with value: 0.992651561543172 and parameters: {'n_estimators': 180, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.992651561543172.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:09,009]\u001b[0m Trial 20 finished with value: 0.9019847328244275 and parameters: {'n_estimators': 180, 'max_depth': 25, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.992651561543172.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:12,917]\u001b[0m Trial 21 finished with value: 0.9923430321592649 and parameters: {'n_estimators': 180, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.992651561543172.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:16,986]\u001b[0m Trial 22 finished with value: 0.978267523722069 and parameters: {'n_estimators': 190, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.992651561543172.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:22,133]\u001b[0m Trial 23 finished with value: 0.9923430321592649 and parameters: {'n_estimators': 180, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.992651561543172.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:26,329]\u001b[0m Trial 24 finished with value: 0.9791411042944786 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.992651561543172.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:29,464]\u001b[0m Trial 25 finished with value: 0.9466300701433363 and parameters: {'n_estimators': 170, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.992651561543172.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:34,219]\u001b[0m Trial 26 finished with value: 0.9577723378212973 and parameters: {'n_estimators': 190, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.992651561543172.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:39,375]\u001b[0m Trial 27 finished with value: 0.9932639314145744 and parameters: {'n_estimators': 170, 'max_depth': 35, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:43,076]\u001b[0m Trial 28 finished with value: 0.9776690119302539 and parameters: {'n_estimators': 170, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:47,388]\u001b[0m Trial 29 finished with value: 0.9571603427172583 and parameters: {'n_estimators': 150, 'max_depth': 35, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:51,495]\u001b[0m Trial 30 finished with value: 0.9348822989911342 and parameters: {'n_estimators': 190, 'max_depth': 20, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:14:56,197]\u001b[0m Trial 31 finished with value: 0.9923430321592649 and parameters: {'n_estimators': 180, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:01,187]\u001b[0m Trial 32 finished with value: 0.9926470588235294 and parameters: {'n_estimators': 200, 'max_depth': 35, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:06,094]\u001b[0m Trial 33 finished with value: 0.9788797061524334 and parameters: {'n_estimators': 200, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:10,415]\u001b[0m Trial 34 finished with value: 0.992651561543172 and parameters: {'n_estimators': 190, 'max_depth': 35, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:13,931]\u001b[0m Trial 35 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 170, 'max_depth': 40, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:19,736]\u001b[0m Trial 36 finished with value: 0.9785801713586292 and parameters: {'n_estimators': 190, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:23,313]\u001b[0m Trial 37 finished with value: 0.9917203311867526 and parameters: {'n_estimators': 130, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:26,915]\u001b[0m Trial 38 finished with value: 0.9460858970453853 and parameters: {'n_estimators': 190, 'max_depth': 40, 'min_samples_leaf': 5}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:29,970]\u001b[0m Trial 39 finished with value: 0.9779546846295162 and parameters: {'n_estimators': 110, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:33,336]\u001b[0m Trial 40 finished with value: 0.9273060476481368 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_leaf': 7}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:37,847]\u001b[0m Trial 41 finished with value: 0.9926470588235294 and parameters: {'n_estimators': 200, 'max_depth': 35, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:42,253]\u001b[0m Trial 42 finished with value: 0.992651561543172 and parameters: {'n_estimators': 190, 'max_depth': 35, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:47,478]\u001b[0m Trial 43 finished with value: 0.9923430321592649 and parameters: {'n_estimators': 180, 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:51,632]\u001b[0m Trial 44 finished with value: 0.9785801713586292 and parameters: {'n_estimators': 190, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:15:55,558]\u001b[0m Trial 45 finished with value: 0.9932639314145744 and parameters: {'n_estimators': 170, 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:16:00,066]\u001b[0m Trial 46 finished with value: 0.9920343137254902 and parameters: {'n_estimators': 160, 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:16:04,327]\u001b[0m Trial 47 finished with value: 0.916156670746634 and parameters: {'n_estimators': 170, 'max_depth': 40, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:16:08,025]\u001b[0m Trial 48 finished with value: 0.9776690119302539 and parameters: {'n_estimators': 170, 'max_depth': 40, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n",
            "\u001b[32m[I 2023-03-11 08:16:11,347]\u001b[0m Trial 49 finished with value: 0.9920343137254902 and parameters: {'n_estimators': 160, 'max_depth': 35, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.9932639314145744.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 7s, sys: 1.67 s, total: 3min 8s\n",
            "Wall time: 3min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Cоздаем объект исследования\n",
        "study_rf = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
        "# Ищем лучшую комбинацию гиперпараметров n_trials раз\n",
        "study_rf.optimize(optuna_rf, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xloRcWOXvlkP",
        "outputId": "01513003-b372-445e-f67e-6c34ee267419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров {'n_estimators': 170, 'max_depth': 35, 'min_samples_leaf': 2}\n",
            "f1_score на обучающем наборе: 0.99\n"
          ]
        }
      ],
      "source": [
        "# Выводим результаты на обучающей выборке\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(study_rf.best_params))\n",
        "print(\"f1_score на обучающем наборе: {:.2f}\".format(study_rf.best_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zRPRHQ5vrEY",
        "outputId": "de29ce88-7c59-47fb-a5ea-a74b49520e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score на тестовом наборе: 0.82\n"
          ]
        }
      ],
      "source": [
        "# Рассчитаем точность для тестовой выборки\n",
        "model_rf_opt = ensemble.RandomForestClassifier(**study_rf.best_params,random_state=random_state, )\n",
        "model_rf_opt.fit(X_train, y_train)\n",
        "y_train_pred = model_rf_opt.predict(X_train)\n",
        "y_test_pred = model_rf_opt.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMPoAWDSCzgL"
      },
      "source": [
        "Для **Случайного леса** получены следующие значения _F1-score_ при подборе гиперпараметров методом **Optuna** на: обучающем наборе - 0.99, тестовом наборе: 0.82. Улучшить метрику случайного леса с помощью **Optuna** не удалось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsj4jn-KyBc0"
      },
      "source": [
        "# 4. Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX4ljBLwB26-"
      },
      "source": [
        "Значения метрик практически не изменились, это значит, что мы не нашли комбинацию внешних параметров лучше, чем были найдены без подбора гиперпараметров. Исключение составляет метод случайного леса, где метрика улучшилась с 0.81 до 0.83."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6beef5ba6e6066e2eca26c3238fb752a2b2f561695d75d02aa01cbdf48771d57"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
